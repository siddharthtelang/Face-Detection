{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from sklearn.decomposition import PCA\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialization\n",
    "subjects = 200\n",
    "types = 2\n",
    "usePCA = True\n",
    "useMDA = False\n",
    "dataset_file = 'Data/data.mat'\n",
    "dataset = 'face'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset\n",
    "data = sio.loadmat(dataset_file)\n",
    "data = data.get(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flatten the dataset\n",
    "flattened = np.zeros(shape=(subjects*types, data.shape[0]*data.shape[1]))\n",
    "\n",
    "# label for neutral and expression - 0 / 1\n",
    "y = np.ones(shape=(subjects*types)) # by default all are one\n",
    "c = 0\n",
    "for i in range(0, data.shape[2], 3):\n",
    "    temp1 = data[:,:,i]\n",
    "    temp2 = data[:,:,i+1]\n",
    "    flattened[c] = temp1.flatten()\n",
    "    flattened[c+1] = temp2.flatten()\n",
    "    y[c+1] = -1 # expression label -1\n",
    "    c += 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "metadata": {},
   "outputs": [],
   "source": [
    "def doPCA(flattened, dim):\n",
    "    pca = PCA(dim)\n",
    "    projected = pca.fit_transform(flattened)\n",
    "    return projected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum dimensions required for 95% retention  132\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Perform PCA if true\n",
    "if usePCA:\n",
    "    pca = PCA().fit(flattened)\n",
    "    plt.figure()\n",
    "    plt.xlabel('Dimensions')\n",
    "    plt.ylabel('Variance Retention')\n",
    "    plt.plot(pca.explained_variance_ratio_.cumsum(), lw=3)\n",
    "    min_dim = (np.where(pca.explained_variance_ratio_.cumsum() > 0.95))[0][0]\n",
    "    print('Minimum dimensions required for 95% retention ', min_dim)\n",
    "    projected = doPCA(flattened, min_dim+10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 142)"
      ]
     },
     "execution_count": 540,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "projected.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 1)"
      ]
     },
     "execution_count": 541,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(320, 1)"
      ]
     },
     "execution_count": 542,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [],
   "source": [
    "projected = flattened"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_data size =  300\n",
      "testing_data size =  100\n"
     ]
    }
   ],
   "source": [
    "# init the training and testing datad\n",
    "training_size = 300 #int(4*projected.shape[0]/5)\n",
    "testing_size = 100 #subjects*types - training_size\n",
    "# training_data = np.zeros(shape=(training_size, projected.shape[1]))\n",
    "# testing_data = np.zeros(shape=(testing_size, projected.shape[1]))\n",
    "\n",
    "y_train = y[:training_size]\n",
    "y_test = y[training_size:]\n",
    "\n",
    "training_data = projected[:training_size]\n",
    "testing_data = projected[training_size:]\n",
    "\n",
    "print('training_data size = ', training_size)\n",
    "print('testing_data size = ', testing_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML ESTIMATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "metadata": {},
   "outputs": [],
   "source": [
    "expression_size = int(training_size / 2)\n",
    "neutral_size = expression_size\n",
    "expression = np.zeros(shape=(expression_size, projected.shape[1]))\n",
    "neutral = np.zeros(shape=(neutral_size, projected.shape[1]))\n",
    "# build up the expression and neutral training set\n",
    "c = 0\n",
    "for i in range(0, training_size, 2):\n",
    "    neutral[c] = projected[i]\n",
    "    expression[c] = projected[i+1]\n",
    "    c += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate class mean and covariance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean\n",
    "mu_expression = np.mean(expression, axis=0)\n",
    "mu_neutral = np.mean(neutral, axis=0)\n",
    "\n",
    "# covariance expression\n",
    "mat = expression - mu_expression\n",
    "cov_expression = (np.dot(mat.T, mat)) / expression_size\n",
    "\n",
    "#covariance neutral\n",
    "mat = neutral - mu_neutral\n",
    "cov_neutral = (np.dot(mat.T, mat)) / neutral_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.135214323188809\n",
      "2.3081721575630496\n"
     ]
    }
   ],
   "source": [
    "# check for zero determinant, add noise if zero\n",
    "while abs(np.linalg.det(cov_expression)) <= 2:\n",
    "    cov_expression = cov_expression + 0.001*np.identity(cov_expression.shape[0])\n",
    "print(np.linalg.det(cov_expression))\n",
    "\n",
    "while abs(np.linalg.det(cov_neutral)) <= 2:\n",
    "    cov_neutral = cov_neutral + 0.001*np.identity(cov_neutral.shape[0])\n",
    "print(np.linalg.det(cov_neutral))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test data using ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of ML Estimate =  87.0\n"
     ]
    }
   ],
   "source": [
    "score = 0\n",
    "for i in range(testing_size):\n",
    "    likelihood_neutral = -0.5*math.log(np.linalg.det(cov_neutral)) - 0.5*np.dot((testing_data[i] - mu_neutral), np.dot(np.linalg.inv(cov_neutral), (testing_data[i] - mu_neutral).T))\n",
    "    likelihood_expression = -0.5*math.log(np.linalg.det(cov_expression)) - 0.5*np.dot((testing_data[i] - mu_expression), np.dot(np.linalg.inv(cov_expression), (testing_data[i] - mu_expression).T))\n",
    "    if likelihood_neutral > likelihood_expression:\n",
    "        predicted_class = 1\n",
    "    else:\n",
    "        predicted_class = -1\n",
    "    if predicted_class == y_test[i]:\n",
    "        score += 1\n",
    "        # print('Correct classification, score = ', score)\n",
    "    # else:\n",
    "        # print('Incorrect classification for test data ', i)\n",
    "\n",
    "accuracy = score*100/testing_size\n",
    "print('Accuracy of ML Estimate = ',accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-NN Estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of  1 -NN =  84.0\n",
      "Accuracy of  2 -NN =  92.5\n",
      "Accuracy of  3 -NN =  91.0\n",
      "Accuracy of  4 -NN =  93.75\n",
      "Accuracy of  5 -NN =  93.0\n",
      "Accuracy of  6 -NN =  94.84536082474227\n",
      "Accuracy of  7 -NN =  95.0\n",
      "Accuracy of  8 -NN =  95.78947368421052\n",
      "Accuracy of  9 -NN =  92.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0xca9970fc70>]"
      ]
     },
     "execution_count": 523,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# K-NN\n",
    "nn = [i for i in range(1,10)]\n",
    "acc = []\n",
    "for k in nn:\n",
    "    score = 0\n",
    "    actual_tests = len(testing_data)\n",
    "\n",
    "    for i in range(1,len(testing_data)):\n",
    "        neutral_score = 0\n",
    "        expression_score = 0\n",
    "\n",
    "        test_class = y_test[i]\n",
    "        dist = np.zeros(shape=(len(training_data)))\n",
    "        \n",
    "        for j in range(len(training_data)):\n",
    "            # d =  np.dot(testing_data[i] - mu[j], np.dot(np.linalg.inv(cov[j]), (testing_data[i] - mu[j]).T))\n",
    "            d = np.linalg.norm(testing_data[i] - training_data[j])\n",
    "            dist[j] = d\n",
    "        \n",
    "        sort = np.argsort(dist)\n",
    "        \n",
    "        predicted_nearest_class = np.zeros(shape=dist.shape[0])\n",
    "        votes_class = np.zeros(shape=subjects)\n",
    "\n",
    "        for l in range(k):\n",
    "            predicted_nearest_class[l] = y_train[int(sort[l])]\n",
    "            if predicted_nearest_class[l] == 1:\n",
    "                neutral_score += 1\n",
    "            else:\n",
    "                expression_score += 1\n",
    "\n",
    "        if neutral_score > expression_score:\n",
    "            predicted_class = 1\n",
    "        elif neutral_score < expression_score:\n",
    "            predicted_class = -1\n",
    "        elif neutral_score == expression_score:\n",
    "            # print('Tie')\n",
    "            actual_tests -= 1\n",
    "            continue\n",
    "\n",
    "        if predicted_class == test_class:\n",
    "            score += 1\n",
    "  \n",
    "    accuracy = (score*100/actual_tests)\n",
    "    print('Accuracy of ',str(k),'-NN = ', accuracy)\n",
    "    acc.append(accuracy)\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.ylim(50,100)\n",
    "plt.xlabel('Number of NN')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.plot(nn, acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.ylim(50,100)\n",
    "plt.xlabel('Number of NN')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.plot(nn, acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lda\n",
    "# Accuracy of  1 -NN =  86.0\n",
    "# Accuracy of  2 -NN =  94.04761904761905\n",
    "# Accuracy of  3 -NN =  95.0\n",
    "# Accuracy of  4 -NN =  94.89795918367346\n",
    "# Accuracy of  5 -NN =  94.0\n",
    "# Accuracy of  6 -NN =  94.79166666666667\n",
    "# Accuracy of  7 -NN =  94.0\n",
    "# Accuracy of  8 -NN =  94.79166666666667\n",
    "# Accuracy of  9 -NN =  92.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PCA\n",
    "# Accuracy of  1 -NN =  78.0\n",
    "# Accuracy of  2 -NN =  87.14285714285714\n",
    "# Accuracy of  3 -NN =  78.0\n",
    "# Accuracy of  4 -NN =  85.46511627906976\n",
    "# Accuracy of  5 -NN =  81.5\n",
    "# Accuracy of  6 -NN =  85.87570621468926\n",
    "# Accuracy of  7 -NN =  80.5\n",
    "# Accuracy of  8 -NN =  84.26966292134831\n",
    "# Accuracy of  9 -NN =  80.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cvxopt\n",
    "import cvxopt.solvers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Form the Kernel\n",
    "def get_kernel(x, kernel_type, param=0.006):\n",
    "    kernel = np.zeros(shape=(x.shape[0], x.shape[0]), dtype=float)\n",
    "    for i in range(kernel.shape[0]):\n",
    "        for j in range(kernel.shape[1]):\n",
    "            if kernel_type == 'rbf':\n",
    "                kernel[i][j] = math.exp( -1*(np.linalg.norm(x[i] - x[j])**2)/(param*param) )\n",
    "            elif kernel_type == 'poly':\n",
    "                kernel[i][j] = math.pow((np.dot(x[i].T, x[j]) +1), param)\n",
    "            else:\n",
    "                kernel[i][j] = np.dot(x[i].T, x[j])\n",
    "    \n",
    "    while abs(np.linalg.det(kernel)) <= 2:\n",
    "        kernel = kernel + 0.001*np.identity(kernel.shape[0])\n",
    "    print(np.linalg.det(kernel))\n",
    "    \n",
    "    return kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# P = cvxopt.matrix(np.outer(y_train,y_train)*kernel)\n",
    "# q = cvxopt.matrix(np.ones(training_size) * -1)\n",
    "# A = cvxopt.matrix(y_train, (1,training_size))\n",
    "# b = cvxopt.matrix(0.0)\n",
    "# G = cvxopt.matrix(np.diag(np.ones(training_size) * -1))\n",
    "# h = cvxopt.matrix(np.zeros(training_size))\n",
    "\n",
    "# solution = cvxopt.solvers.qp(P, q, G, h, A, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_kernel(x, y, kernel_type='rbf', param=0.006):\n",
    "    \"\"\"Evaluates the kernel at a specific test data\n",
    "\n",
    "    Args:\n",
    "        x (np array): Training data\n",
    "        y (np array): Test point\n",
    "        kernel_type (str, optional): rbf or poly. Defaults to 'rbf'.\n",
    "        param (int, optional): scale of the kernel. Defaults to 10.\n",
    "\n",
    "    Returns:\n",
    "        [float]: [kernel evaluated at y]\n",
    "    \"\"\"\n",
    "    val = np.zeros(shape=(x.shape[0]), dtype=float)\n",
    "    for i in range(x.shape[0]):\n",
    "        if kernel_type == 'rbf':\n",
    "            val[i] += math.exp( -1*(np.linalg.norm(x[i] - y)**2)/(param*param) )\n",
    "        elif kernel_type == 'poly':\n",
    "            val[i] += math.pow((np.dot(x[i].T, y) +1), param)\n",
    "        else:\n",
    "            val[i] = np.dot(x[i].T, y)\n",
    "        \n",
    "    return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tr = training_data\n",
    "# te = testing_data\n",
    "# ytr = y_train\n",
    "# yte = y_test\n",
    "# trs = training_size\n",
    "# tes = testing_size\n",
    "\n",
    "# training_data = tr\n",
    "# testing_data = te\n",
    "# y_train = ytr\n",
    "# y_test = yte\n",
    "# training_size = 300\n",
    "# testing_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_data = np.array([[1,1], [2,2], [2,0], [0,0], [1,0] , [0,1]])\n",
    "# testing_data = np.array([[1.5,1.5], [1.75,1.75], [0.5,0.25], [0.5,0.5]])\n",
    "# y_train = np.array([1,1,1,-1,-1,-1], dtype=float)\n",
    "# y_test = np.array([1,1,-1,-1], dtype=float)\n",
    "# training_size = 6\n",
    "# testing_size = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.87\n"
     ]
    }
   ],
   "source": [
    "gam = [0.005]\n",
    "for g in gam:\n",
    "    clf = svm.SVC(kernel='rbf')\n",
    "    clf.fit(training_data, y_train)\n",
    "    pred = clf.predict(testing_data)\n",
    "    print(accuracy_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.11742175])"
      ]
     },
     "execution_count": 551,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.006773038322295767"
      ]
     },
     "execution_count": 552,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1/(training_size*training_data.var())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'scale'"
      ]
     },
     "execution_count": 462,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = clf.predict(testing_data)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "# accuracy_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = get_kernel(training_data, kernel_type=kernel_type, param=0.0009118136546038253)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.671444945969816\n"
     ]
    }
   ],
   "source": [
    "# while abs(np.linalg.det(kernel)) <= 2:\n",
    "#     kernel = kernel + 0.001*np.identity(kernel.shape[0])\n",
    "# print(np.linalg.det(kernel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.456291330358944\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -1.1228e+02 -2.6206e+02  1e+02  2e-14  1e+00\n",
      " 1: -1.4119e+02 -1.4348e+02  2e+00  6e-15  2e-01\n",
      " 2: -1.4955e+02 -1.4982e+02  3e-01  3e-15  1e-16\n",
      " 3: -1.4955e+02 -1.4955e+02  3e-03  3e-15  1e-16\n",
      " 4: -1.4955e+02 -1.4955e+02  3e-05  5e-15  1e-16\n",
      "Optimal solution found.\n",
      "50\n",
      "Cross Validation Accuracy with  rbf  kernel with param  1  is =  50.0\n",
      "2.403095044255576\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -1.1245e+02 -2.6743e+02  2e+02  6e-15  2e+00\n",
      " 1: -1.4080e+02 -1.4714e+02  6e+00  7e-15  3e-01\n",
      " 2: -1.4991e+02 -1.5062e+02  7e-01  1e-14  2e-16\n",
      " 3: -1.4991e+02 -1.4991e+02  7e-03  3e-15  2e-16\n",
      " 4: -1.4991e+02 -1.4991e+02  7e-05  3e-15  1e-16\n",
      "Optimal solution found.\n",
      "50\n",
      "Cross Validation Accuracy with  rbf  kernel with param  2  is =  50.0\n",
      "2.2221035872150527\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -1.1161e+02 -2.8064e+02  2e+02  3e-15  2e+00\n",
      " 1: -1.3765e+02 -1.5740e+02  2e+01  1e-14  4e-01\n",
      " 2: -1.4865e+02 -1.5041e+02  2e+00  8e-15  3e-04\n",
      " 3: -1.4866e+02 -1.4868e+02  2e-02  3e-15  3e-06\n",
      " 4: -1.4866e+02 -1.4866e+02  2e-04  3e-15  3e-08\n",
      " 5: -1.4866e+02 -1.4866e+02  2e-06  3e-15  3e-10\n",
      "Optimal solution found.\n",
      "63\n",
      "Cross Validation Accuracy with  rbf  kernel with param  3  is =  63.0\n",
      "2.1283027382862225\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -1.0036e+02 -2.7443e+02  2e+02  2e-14  2e+00\n",
      " 1: -1.2028e+02 -1.5639e+02  4e+01  4e-15  5e-01\n",
      " 2: -1.3143e+02 -1.3428e+02  3e+00  6e-15  2e-03\n",
      " 3: -1.3145e+02 -1.3150e+02  5e-02  3e-15  3e-05\n",
      " 4: -1.3146e+02 -1.3146e+02  1e-03  3e-15  4e-07\n",
      " 5: -1.3146e+02 -1.3146e+02  6e-05  3e-15  4e-09\n",
      "Optimal solution found.\n",
      "73\n",
      "Cross Validation Accuracy with  rbf  kernel with param  4  is =  73.0\n",
      "2.0685780124473876\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -8.3825e+01 -2.5093e+02  6e+02  2e+01  2e+00\n",
      " 1: -1.0102e+02 -2.0247e+02  1e+02  2e+00  2e-01\n",
      " 2: -1.0790e+02 -1.2056e+02  1e+01  7e-02  7e-03\n",
      " 3: -1.0893e+02 -1.0965e+02  7e-01  2e-03  2e-04\n",
      " 4: -1.0906e+02 -1.0909e+02  3e-02  5e-05  5e-06\n",
      " 5: -1.0907e+02 -1.0907e+02  2e-03  8e-07  8e-08\n",
      " 6: -1.0907e+02 -1.0907e+02  9e-05  8e-09  8e-10\n",
      "Optimal solution found.\n",
      "74\n",
      "Cross Validation Accuracy with  rbf  kernel with param  5  is =  74.0\n",
      "2.7518545506849352\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -7.1399e+01 -2.2211e+02  7e+02  2e+01  2e+00\n",
      " 1: -7.6562e+01 -1.8511e+02  1e+02  1e+00  1e-01\n",
      " 2: -9.0501e+01 -1.0564e+02  2e+01  5e-02  5e-03\n",
      " 3: -9.2337e+01 -9.3920e+01  2e+00  4e-03  4e-04\n",
      " 4: -9.2635e+01 -9.2738e+01  1e-01  1e-04  1e-05\n",
      " 5: -9.2669e+01 -9.2674e+01  6e-03  2e-06  2e-07\n",
      " 6: -9.2671e+01 -9.2671e+01  3e-04  3e-08  2e-09\n",
      " 7: -9.2671e+01 -9.2671e+01  2e-05  3e-10  2e-11\n",
      "Optimal solution found.\n",
      "78\n",
      "Cross Validation Accuracy with  rbf  kernel with param  6  is =  78.0\n",
      "2.486090879917653\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -6.3767e+01 -2.0122e+02  8e+02  2e+01  2e+00\n",
      " 1: -6.2636e+01 -1.7426e+02  1e+02  9e-01  8e-02\n",
      " 2: -7.9776e+01 -9.4885e+01  2e+01  4e-02  3e-03\n",
      " 3: -8.2003e+01 -8.3516e+01  2e+00  2e-03  2e-04\n",
      " 4: -8.2393e+01 -8.2540e+01  1e-01  1e-04  1e-05\n",
      " 5: -8.2449e+01 -8.2458e+01  9e-03  2e-06  2e-07\n",
      " 6: -8.2453e+01 -8.2454e+01  4e-04  4e-08  4e-09\n",
      " 7: -8.2454e+01 -8.2454e+01  1e-05  5e-10  4e-11\n",
      "Optimal solution found.\n",
      "75\n",
      "Cross Validation Accuracy with  rbf  kernel with param  7  is =  75.0\n",
      "2.374911988551327\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -5.9246e+01 -1.8771e+02  8e+02  2e+01  2e+00\n",
      " 1: -5.4870e+01 -1.6471e+02  1e+02  7e-01  6e-02\n",
      " 2: -7.3489e+01 -8.7194e+01  1e+01  2e-02  2e-03\n",
      " 3: -7.5696e+01 -7.7192e+01  1e+00  2e-03  1e-04\n",
      " 4: -7.6103e+01 -7.6264e+01  2e-01  1e-04  1e-05\n",
      " 5: -7.6169e+01 -7.6179e+01  9e-03  3e-06  2e-07\n",
      " 6: -7.6174e+01 -7.6175e+01  4e-04  4e-08  4e-09\n",
      " 7: -7.6174e+01 -7.6174e+01  2e-05  5e-10  5e-11\n",
      "Optimal solution found.\n",
      "65\n",
      "Cross Validation Accuracy with  rbf  kernel with param  8  is =  65.0\n",
      "2.2936952633010783\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -5.6626e+01 -1.7934e+02  8e+02  2e+01  2e+00\n",
      " 1: -5.0327e+01 -1.5742e+02  1e+02  5e-01  4e-02\n",
      " 2: -6.9803e+01 -8.2637e+01  1e+01  1e-02  1e-03\n",
      " 3: -7.1913e+01 -7.3287e+01  1e+00  1e-03  8e-05\n",
      " 4: -7.2302e+01 -7.2445e+01  1e-01  7e-05  6e-06\n",
      " 5: -7.2362e+01 -7.2370e+01  8e-03  2e-06  2e-07\n",
      " 6: -7.2366e+01 -7.2367e+01  4e-04  3e-08  3e-09\n",
      " 7: -7.2366e+01 -7.2366e+01  2e-05  4e-10  3e-11\n",
      "Optimal solution found.\n",
      "60\n",
      "Cross Validation Accuracy with  rbf  kernel with param  9  is =  60.0\n",
      "2.6929944970160147\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -5.5164e+01 -1.7430e+02  8e+02  2e+01  2e+00\n",
      " 1: -4.7505e+01 -1.5200e+02  1e+02  2e-01  2e-02\n",
      " 2: -6.7787e+01 -7.9216e+01  1e+01  5e-03  4e-04\n",
      " 3: -6.9681e+01 -7.0945e+01  1e+00  4e-04  3e-05\n",
      " 4: -7.0037e+01 -7.0157e+01  1e-01  2e-05  2e-06\n",
      " 5: -7.0088e+01 -7.0095e+01  7e-03  5e-07  4e-08\n",
      " 6: -7.0092e+01 -7.0092e+01  3e-04  6e-09  5e-10\n",
      " 7: -7.0092e+01 -7.0092e+01  2e-05  7e-11  6e-12\n",
      "Optimal solution found.\n",
      "58\n",
      "Cross Validation Accuracy with  rbf  kernel with param  10  is =  57.99999999999999\n"
     ]
    }
   ],
   "source": [
    "params = [1,2,3,4,5,6,7,8,9,10]\n",
    "# params = [6,6.1,6.2,6.3,6.4,6.5,6.6,6.7,6.8,6.9,7]\n",
    "# params = [0.00091, 0.002, 0.003, 0.008, 0.2, 0.3, 0.0002, 1,2,3,4,5]\n",
    "# params = [3]\n",
    "# params = [0.006773038322295767]\n",
    "# params = [2.1,2.2,2.3,2.4,2.5,2.6,2.7,2.8,2.9]\n",
    "# params = [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1,2,3,4,5,6]\n",
    "scores = []\n",
    "# param = 1\n",
    "for param in params:\n",
    "    # C = 0.5\n",
    "    threshold = 1e-5\n",
    "    kernel_type = 'rbf'\n",
    "    kernel = get_kernel(training_data, kernel_type=kernel_type, param=param)\n",
    "\n",
    "    P = cvxopt.matrix(np.outer(y_train,y_train)*kernel)\n",
    "    q = cvxopt.matrix(np.ones(training_size) * -1)\n",
    "    A = cvxopt.matrix(y_train, (1,training_size))\n",
    "    b = cvxopt.matrix(0.0)\n",
    "    G = cvxopt.matrix(np.diag(np.ones(training_size) * -1))\n",
    "    # G = cvxopt.matrix(np.vstack((np.eye(training_size)*-1,np.eye(training_size))))\n",
    "    h = cvxopt.matrix(np.zeros(training_size))\n",
    "    # h = cvxopt.matrix(np.hstack((np.zeros(training_size), np.ones(training_size) * C)))\n",
    "\n",
    "    solution = cvxopt.solvers.qp(P, q, G, h, A, b)\n",
    "\n",
    "    # support vectors\n",
    "    sv = np.ravel(solution['x'])\n",
    "\n",
    "    for i in range(sv.shape[0]):\n",
    "        if sv[i] <= threshold:\n",
    "            sv[i] = 0\n",
    "\n",
    "    # hyperplane\n",
    "    # theta = np.dot((sv*y_train).T, training_data)\n",
    "\n",
    "    # Find the intercept\n",
    "    idx = np.argsort(sv)\n",
    "    idx = idx[::-1][0]\n",
    "\n",
    "    k1 = evaluate_kernel(training_data, training_data[idx], kernel_type=kernel_type, param=param)\n",
    "    sum = 0.0\n",
    "    for m in range(training_size):\n",
    "        sum += k1[m]*sv[m]*y_train[m]\n",
    "    theta0 = 1/y_train[idx] - sum\n",
    "\n",
    "    # cross-validation\n",
    "    score = 0\n",
    "    for i in range(len(testing_data)):\n",
    "        # test = np.dot((sv*y_train).T, evaluate_kernel(training_data, testing_data[i], kernel_type, param)) + theta0\n",
    "        # test = np.dot(theta.T, testing_data[i]) + theta0\n",
    "\n",
    "        k2 = evaluate_kernel(training_data, testing_data[i], kernel_type=kernel_type, param=param)\n",
    "        test = 0.0\n",
    "\n",
    "        for m in range(training_size):\n",
    "            test += k2[m]*y_train[m]*sv[m]\n",
    "\n",
    "        test += theta0\n",
    "\n",
    "        if (test*y_test[i] >= 0):\n",
    "            score += 1\n",
    "            # print('Correct')\n",
    "        # else:\n",
    "            # print('Incorrect')\n",
    "\n",
    "    print(score)\n",
    "    accuracy = (score/testing_size)*100\n",
    "    scores.append(accuracy)\n",
    "    print('Cross Validation Accuracy with ', kernel_type, ' kernel with param ', str(param), ' is = ', str(accuracy))\n",
    "\n",
    "# label = kernel_type + ' Kernel Parameter'\n",
    "# label = 'Poly Kernel with Slack'\n",
    "# plt.xlabel(label)\n",
    "# plt.ylabel('Accuracy')\n",
    "# plt.plot(np.array(params), np.array(scores))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ADA Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_support_vector_multipler(kernel, training_data, training_size, y_train, threshold = 1e-6, C=1):\n",
    "\n",
    "    P = cvxopt.matrix(np.outer(y_train,y_train)*kernel)\n",
    "    q = cvxopt.matrix(np.ones(training_size) * -1)\n",
    "    A = cvxopt.matrix(y_train, (1,training_size))\n",
    "    b = cvxopt.matrix(0.0)\n",
    "    G = cvxopt.matrix(np.diag(np.ones(training_size) * -1))\n",
    "    # G = cvxopt.matrix(np.vstack((np.eye(training_size)*-1,np.eye(training_size))))\n",
    "    h = cvxopt.matrix(np.zeros(training_size))\n",
    "    # h = cvxopt.matrix(np.hstack((np.zeros(training_size), np.ones(training_size) * C)))\n",
    "\n",
    "    solution = cvxopt.solvers.qp(P, q, G, h, A, b)\n",
    "\n",
    "    # support vectors\n",
    "    sv = np.ravel(solution['x'])\n",
    "\n",
    "    for i in range(sv.shape[0]):\n",
    "        if sv[i] <= threshold:\n",
    "            sv[i] = 0\n",
    "    \n",
    "    return sv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_train_validation(subjects, types, projected, training_size, testing_size):\n",
    "    # init the training and testing data\n",
    "\n",
    "    validation_size = subjects*types - testing_size \n",
    "\n",
    "    y_train = y[:training_size]\n",
    "    y_validation = y[:validation_size]\n",
    "    y_test = y[training_size:]\n",
    "\n",
    "    training_data = projected[:training_size]\n",
    "    validation_data = projected[:validation_size]\n",
    "    testing_data = projected[validation_size:]\n",
    "\n",
    "    print('training_data size = ', training_size)\n",
    "    print('Validation size = ', validation_size)\n",
    "    print('testing_data size = ', testing_size)\n",
    "\n",
    "    return training_data, validation_data, testing_data, y_train, y_validation, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_data size =  120\n",
      "Validation size =  300\n",
      "testing_data size =  100\n",
      "2.10823972084102\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -2.1963e+01 -5.9396e+01  3e+02  2e+01  2e+00\n",
      " 1: -2.5906e+01 -5.5023e+01  8e+01  4e+00  4e-01\n",
      " 2: -1.8973e+01 -2.8821e+01  1e+01  1e-01  1e-02\n",
      " 3: -2.0060e+01 -2.1177e+01  1e+00  7e-03  8e-04\n",
      " 4: -2.0407e+01 -2.0514e+01  1e-01  4e-04  4e-05\n",
      " 5: -2.0462e+01 -2.0470e+01  8e-03  1e-05  1e-06\n",
      " 6: -2.0467e+01 -2.0468e+01  3e-04  2e-07  2e-08\n",
      " 7: -2.0468e+01 -2.0468e+01  1e-05  2e-09  2e-10\n",
      "Optimal solution found.\n",
      "Error in iteration  1  is =  0.31666666666666676\n",
      "training_data size =  120\n",
      "Validation size =  300\n",
      "testing_data size =  100\n",
      "2.10823972084102\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -2.1963e+01 -5.9396e+01  3e+02  2e+01  2e+00\n",
      " 1: -2.5906e+01 -5.5023e+01  8e+01  4e+00  4e-01\n",
      " 2: -1.8973e+01 -2.8821e+01  1e+01  1e-01  1e-02\n",
      " 3: -2.0060e+01 -2.1177e+01  1e+00  7e-03  8e-04\n",
      " 4: -2.0407e+01 -2.0514e+01  1e-01  4e-04  4e-05\n",
      " 5: -2.0462e+01 -2.0470e+01  8e-03  1e-05  1e-06\n",
      " 6: -2.0467e+01 -2.0468e+01  3e-04  2e-07  2e-08\n",
      " 7: -2.0468e+01 -2.0468e+01  1e-05  2e-09  2e-10\n",
      "Optimal solution found.\n",
      "Error in iteration  2  is =  0.9395694397857133\n",
      "training_data size =  140\n",
      "Validation size =  300\n",
      "testing_data size =  100\n",
      "2.1085133820100674\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -2.5167e+01 -6.8300e+01  4e+02  2e+01  2e+00\n",
      " 1: -2.9812e+01 -6.3073e+01  1e+02  4e+00  4e-01\n",
      " 2: -2.1205e+01 -3.2754e+01  2e+01  3e-01  3e-02\n",
      " 3: -2.1835e+01 -2.3432e+01  2e+00  1e-02  1e-03\n",
      " 4: -2.2322e+01 -2.2485e+01  2e-01  7e-04  7e-05\n",
      " 5: -2.2410e+01 -2.2421e+01  1e-02  2e-05  2e-06\n",
      " 6: -2.2417e+01 -2.2417e+01  5e-04  4e-07  4e-08\n",
      " 7: -2.2417e+01 -2.2417e+01  2e-05  5e-09  5e-10\n",
      "Optimal solution found.\n",
      "Error in iteration  2  is =  0.9359891473857378\n",
      "training_data size =  160\n",
      "Validation size =  300\n",
      "testing_data size =  100\n",
      "2.0748337478188548\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -2.8738e+01 -7.7838e+01  4e+02  2e+01  2e+00\n",
      " 1: -3.3952e+01 -7.3167e+01  1e+02  4e+00  4e-01\n",
      " 2: -2.4073e+01 -3.7525e+01  2e+01  5e-01  4e-02\n",
      " 3: -2.3749e+01 -2.6070e+01  2e+00  1e-02  1e-03\n",
      " 4: -2.4385e+01 -2.4637e+01  3e-01  9e-04  8e-05\n",
      " 5: -2.4516e+01 -2.4536e+01  2e-02  4e-05  3e-06\n",
      " 6: -2.4529e+01 -2.4530e+01  9e-04  7e-07  6e-08\n",
      " 7: -2.4530e+01 -2.4530e+01  3e-05  8e-09  7e-10\n",
      " 8: -2.4530e+01 -2.4530e+01  4e-07  8e-11  7e-12\n",
      "Optimal solution found.\n",
      "Error in iteration  2  is =  0.9304052948608025\n",
      "training_data size =  180\n",
      "Validation size =  300\n",
      "testing_data size =  100\n",
      "2.3826433786943535\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -3.2527e+01 -8.7927e+01  5e+02  2e+01  2e+00\n",
      " 1: -3.8232e+01 -8.4795e+01  1e+02  5e+00  4e-01\n",
      " 2: -2.8458e+01 -4.3839e+01  3e+01  5e-01  4e-02\n",
      " 3: -2.8101e+01 -3.0574e+01  3e+00  1e-02  1e-03\n",
      " 4: -2.8766e+01 -2.9021e+01  3e-01  8e-04  7e-05\n",
      " 5: -2.8895e+01 -2.8916e+01  2e-02  3e-05  2e-06\n",
      " 6: -2.8909e+01 -2.8910e+01  1e-03  5e-07  4e-08\n",
      " 7: -2.8909e+01 -2.8909e+01  6e-05  5e-09  4e-10\n",
      " 8: -2.8909e+01 -2.8909e+01  3e-06  6e-11  5e-12\n",
      "Optimal solution found.\n",
      "Error in iteration  2  is =  0.9304052948608025\n",
      "training_data size =  200\n",
      "Validation size =  300\n",
      "testing_data size =  100\n",
      "2.3082294732072706\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -3.4685e+01 -9.4220e+01  6e+02  2e+01  2e+00\n",
      " 1: -4.0954e+01 -8.9097e+01  1e+02  5e+00  4e-01\n",
      " 2: -3.0779e+01 -4.6168e+01  3e+01  6e-01  5e-02\n",
      " 3: -2.9383e+01 -3.2313e+01  3e+00  2e-02  1e-03\n",
      " 4: -3.0117e+01 -3.0431e+01  3e-01  1e-03  9e-05\n",
      " 5: -3.0276e+01 -3.0300e+01  2e-02  4e-05  3e-06\n",
      " 6: -3.0292e+01 -3.0293e+01  1e-03  7e-07  6e-08\n",
      " 7: -3.0293e+01 -3.0293e+01  3e-05  8e-09  6e-10\n",
      " 8: -3.0293e+01 -3.0293e+01  4e-07  8e-11  6e-12\n",
      "Optimal solution found.\n",
      "Error in iteration  2  is =  0.9304052948608025\n",
      "training_data size =  220\n",
      "Validation size =  300\n",
      "testing_data size =  100\n",
      "2.3791650884457036\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -3.7424e+01 -1.0182e+02  6e+02  2e+01  2e+00\n",
      " 1: -4.4128e+01 -9.6373e+01  2e+02  5e+00  4e-01\n",
      " 2: -3.2947e+01 -4.9427e+01  3e+01  7e-01  6e-02\n",
      " 3: -3.0807e+01 -3.4275e+01  4e+00  2e-02  1e-03\n",
      " 4: -3.1687e+01 -3.2082e+01  4e-01  1e-03  1e-04\n",
      " 5: -3.1887e+01 -3.1919e+01  3e-02  5e-05  4e-06\n",
      " 6: -3.1908e+01 -3.1910e+01  1e-03  1e-06  7e-08\n",
      " 7: -3.1909e+01 -3.1909e+01  5e-05  1e-08  9e-10\n",
      " 8: -3.1909e+01 -3.1909e+01  3e-06  1e-10  9e-12\n",
      "Optimal solution found.\n",
      "Error in iteration  2  is =  0.9265764738151624\n",
      "training_data size =  240\n",
      "Validation size =  300\n",
      "testing_data size =  100\n",
      "2.181681332729446\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -4.0002e+01 -1.0901e+02  7e+02  2e+01  2e+00\n",
      " 1: -4.7138e+01 -1.0259e+02  2e+02  5e+00  4e-01\n",
      " 2: -3.4978e+01 -5.2263e+01  4e+01  8e-01  6e-02\n",
      " 3: -3.2602e+01 -3.6391e+01  4e+00  2e-02  1e-03\n",
      " 4: -3.3559e+01 -3.4005e+01  5e-01  1e-03  1e-04\n",
      " 5: -3.3786e+01 -3.3823e+01  4e-02  6e-05  4e-06\n",
      " 6: -3.3811e+01 -3.3812e+01  2e-03  1e-06  8e-08\n",
      " 7: -3.3812e+01 -3.3812e+01  5e-05  1e-08  9e-10\n",
      " 8: -3.3812e+01 -3.3812e+01  8e-07  1e-10  9e-12\n",
      "Optimal solution found.\n",
      "Error in iteration  2  is =  0.9265764738151624\n",
      "training_data size =  260\n",
      "Validation size =  300\n",
      "testing_data size =  100\n",
      "2.211263075605119\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -4.3093e+01 -1.1745e+02  7e+02  3e+01  2e+00\n",
      " 1: -5.0785e+01 -1.1169e+02  2e+02  5e+00  4e-01\n",
      " 2: -3.7924e+01 -5.6273e+01  4e+01  9e-01  7e-02\n",
      " 3: -3.3915e+01 -3.8559e+01  5e+00  2e-02  2e-03\n",
      " 4: -3.4988e+01 -3.5552e+01  6e-01  2e-03  1e-04\n",
      " 5: -3.5259e+01 -3.5311e+01  5e-02  9e-05  6e-06\n",
      " 6: -3.5291e+01 -3.5294e+01  3e-03  2e-06  1e-07\n",
      " 7: -3.5293e+01 -3.5293e+01  1e-04  3e-08  2e-09\n",
      " 8: -3.5293e+01 -3.5293e+01  9e-06  3e-10  2e-11\n",
      "Optimal solution found.\n",
      "Error in iteration  2  is =  0.9245937272402925\n",
      "training_data size =  280\n",
      "Validation size =  300\n",
      "testing_data size =  100\n",
      "2.284053692138756\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -4.6130e+01 -1.2599e+02  8e+02  3e+01  2e+00\n",
      " 1: -5.4136e+01 -1.2024e+02  2e+02  6e+00  4e-01\n",
      " 2: -4.0327e+01 -6.0032e+01  5e+01  1e+00  7e-02\n",
      " 3: -3.5948e+01 -4.1010e+01  6e+00  2e-02  1e-03\n",
      " 4: -3.7160e+01 -3.7793e+01  7e-01  2e-03  1e-04\n",
      " 5: -3.7468e+01 -3.7526e+01  6e-02  9e-05  6e-06\n",
      " 6: -3.7505e+01 -3.7508e+01  3e-03  2e-06  1e-07\n",
      " 7: -3.7507e+01 -3.7507e+01  2e-04  3e-08  2e-09\n",
      " 8: -3.7507e+01 -3.7507e+01  1e-05  4e-10  2e-11\n",
      "Optimal solution found.\n",
      "Error in iteration  2  is =  0.9245937272402925\n",
      "training_data size =  300\n",
      "Validation size =  300\n",
      "testing_data size =  100\n",
      "2.56017465245931\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -4.8355e+01 -1.3245e+02  9e+02  3e+01  2e+00\n",
      " 1: -5.6226e+01 -1.2641e+02  2e+02  6e+00  4e-01\n",
      " 2: -4.1319e+01 -6.2554e+01  5e+01  1e+00  6e-02\n",
      " 3: -3.7525e+01 -4.2803e+01  6e+00  2e-02  1e-03\n",
      " 4: -3.8819e+01 -3.9499e+01  7e-01  2e-03  1e-04\n",
      " 5: -3.9152e+01 -3.9215e+01  6e-02  9e-05  6e-06\n",
      " 6: -3.9192e+01 -3.9196e+01  3e-03  2e-06  1e-07\n",
      " 7: -3.9195e+01 -3.9195e+01  2e-04  3e-08  2e-09\n",
      " 8: -3.9195e+01 -3.9195e+01  1e-05  4e-10  2e-11\n",
      "Optimal solution found.\n",
      "Error in iteration  2  is =  0.9245937272402925\n",
      "training_data size =  320\n",
      "Validation size =  300\n",
      "testing_data size =  100\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11024/1997445991.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     36\u001b[0m         \u001b[0mtraining_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtesting_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_validation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_test_train_validation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubjects\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtypes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprojected\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_size_weak\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtesting_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m         \u001b[0mkernel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_kernel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernel_type\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkernel_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m         \u001b[1;31m# find the multiplers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11024/2556259774.py\u001b[0m in \u001b[0;36mget_kernel\u001b[1;34m(x, kernel_type, param)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;32mwhile\u001b[0m \u001b[0mabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkernel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m         \u001b[0mkernel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkernel\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m0.001\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0midentity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkernel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkernel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\numpy\\core\\numeric.py\u001b[0m in \u001b[0;36midentity\u001b[1;34m(n, dtype, like)\u001b[0m\n\u001b[0;32m   2165\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2166\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0meye\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2167\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0meye\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlike\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlike\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2168\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2169\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\numpy\\lib\\twodim_base.py\u001b[0m in \u001b[0;36meye\u001b[1;34m(N, M, k, dtype, order, like)\u001b[0m\n\u001b[0;32m    212\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mM\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    213\u001b[0m         \u001b[0mM\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mN\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 214\u001b[1;33m     \u001b[0mm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mM\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    215\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mk\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mM\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    216\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mm\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "iterations = 5\n",
    "training_size = 300\n",
    "testing_size = 100\n",
    "\n",
    "# weight vector\n",
    "w = np.zeros(shape=(iterations, training_size))\n",
    "P = np.zeros(shape=(iterations, training_size))\n",
    "a = np.zeros(shape=(iterations))\n",
    "test = np.zeros(shape=training_size)\n",
    "w[0] = 1/training_size*np.ones(training_size)\n",
    "theta0 = np.zeros(shape=(iterations))\n",
    "theta = np.zeros(shape=(iterations, training_data.shape[1])) \n",
    "\n",
    "for k in range(iterations-1):\n",
    "\n",
    "    threshold = 1e-5\n",
    "    kernel_type = 'linear'\n",
    "\n",
    "    # calculate P for each sample\n",
    "    for i in range(training_size-1):\n",
    "        P[k][i] = w[k][i] / (np.sum(w[k]))\n",
    "\n",
    "    # training size for weak classifier\n",
    "    training_size_weak = 100\n",
    "    # testing size\n",
    "    testing_size = 100\n",
    "    error = 0.0\n",
    "\n",
    "    while(True):\n",
    "\n",
    "        ei = np.zeros(shape=(training_size))\n",
    "\n",
    "        training_size_weak += 20\n",
    "        # get the test, train, validation data\n",
    "        training_data, validation_data, testing_data, y_train, y_validation, y_test = get_test_train_validation(subjects, types, projected, training_size_weak, testing_size)\n",
    "\n",
    "        kernel = get_kernel(training_data, kernel_type=kernel_type)\n",
    "\n",
    "        # find the multiplers\n",
    "        sv = get_support_vector_multipler(kernel, training_data, training_size_weak, y_train)\n",
    "\n",
    "        # hyperplane\n",
    "        theta[k] = np.dot((sv*y_train).T, training_data)\n",
    "\n",
    "        # Find the intercept\n",
    "        idx = np.argsort(sv)\n",
    "        idx = idx[::-1][0]\n",
    "\n",
    "        theta0[k] = 1/y_train[idx] - np.dot(theta[k].T, training_data[idx])\n",
    "\n",
    "        # cross-validation\n",
    "        error = 0.0\n",
    "        for i in range(len(validation_data)):\n",
    "            test[i] = np.dot(theta[k].T, validation_data[i]) + theta0[k]\n",
    "\n",
    "            if (test[i]*y_validation[i] < 0):\n",
    "                error += P[k][i]\n",
    "        \n",
    "        print('Error in iteration ', str(k+1), ' is = ', str(error))\n",
    "\n",
    "        if error < 0.6:\n",
    "            break\n",
    "    \n",
    "    # update the coefficient\n",
    "    if error != 0:\n",
    "        a[k] = 0.5*math.log((1-error)/error)\n",
    "\n",
    "    # update next weights\n",
    "\n",
    "    for i in range(training_size):\n",
    "        w[k+1][i] = w[k][i] * math.exp( (-1*y_validation[i]*test[i]) )\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = 0\n",
    "for i in range(len(validation_data)):\n",
    "    test = 0\n",
    "    for k in range(iterations):\n",
    "        test += a[k] * np.dot(theta[k].T, validation_data[i]) + theta0[k]\n",
    "    if (test*y_validation[i] > 0):\n",
    "        score += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "274"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = 0\n",
    "for i in range(len(testing_data)):\n",
    "    test = 0\n",
    "    for k in range(iterations):\n",
    "        test += a[k] * np.dot(theta[k].T, testing_data[i]) + theta0[k]\n",
    "    if (test*y_test[i] > 0):\n",
    "        score += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [],
   "source": [
    "neutral = np.zeros(shape=(subjects, flattened.shape[1]))\n",
    "expression = np.zeros(shape=(subjects, flattened.shape[1]))\n",
    "\n",
    "c = 0\n",
    "for i in range(0, subjects*types, 2):\n",
    "    neutral[c] = flattened[i]\n",
    "    expression[c] = flattened[i+1]\n",
    "    c+=1\n",
    "mu_neutral = np.mean(neutral, axis=0)\n",
    "mu_expression = np.mean(expression, axis=0)\n",
    "\n",
    "mat = neutral - mu_neutral\n",
    "cov_neutral = np.dot(mat.T, mat) / subjects\n",
    "mat = expression - mu_neutral\n",
    "cov_expression = np.dot(mat.T, mat) / subjects\n",
    "mat = (mu_neutral - mu_expression).reshape((1, flattened.shape[1]))\n",
    "sigma_b = np.dot(mat.T, mat)\n",
    "sigma_w = cov_neutral + cov_neutral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.937939257947475\n",
      "5.39901519806892\n"
     ]
    }
   ],
   "source": [
    "# while abs(np.linalg.det(sigma_b)) <= 2:\n",
    "sigma_b = sigma_b + 0.999*np.identity(sigma_b.shape[0])\n",
    "print(np.linalg.det(sigma_b))\n",
    "\n",
    "# while abs(np.linalg.det(sigma_w)) <= 2:\n",
    "sigma_w = sigma_w + 0.868*np.identity(sigma_w.shape[0])\n",
    "print(np.linalg.det(sigma_w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.dot(np.linalg.inv(sigma_w), sigma_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [],
   "source": [
    "val, vec = np.linalg.eig(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = val.argsort()[::-1]\n",
    "vec_  = vec[:, idx]\n",
    "vec_.shape\n",
    "dim = 1\n",
    "vec__ = vec_[:,:dim]\n",
    "vec__.shape\n",
    "f = np.dot(flattened, vec__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 1)"
      ]
     },
     "execution_count": 434,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {},
   "outputs": [],
   "source": [
    "# projected_bcp = projected\n",
    "projected  = f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(504,)"
      ]
     },
     "execution_count": 493,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mu_neutral.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [],
   "source": [
    "check = np.dot(np.linalg.inv(sigma_w), (mu_neutral - mu_expression))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {},
   "outputs": [],
   "source": [
    "check = check.reshape((check.shape[0],1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(504, 1)"
      ]
     },
     "execution_count": 498,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec__.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = np.dot(flattened, check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 1)"
      ]
     },
     "execution_count": 511,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 504)"
      ]
     },
     "execution_count": 512,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flattened.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cdfa986811ede5aec55e936b833b50dd727f4374221054198d85d31e15300e88"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
