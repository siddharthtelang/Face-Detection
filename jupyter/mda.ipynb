{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from sklearn.decomposition import PCA\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialization\n",
    "subjects = 200\n",
    "types = 3\n",
    "usePCA = True\n",
    "useMDA = False\n",
    "# dataset_file = 'Data/pose.mat'\n",
    "dataset_file = 'Data/data.mat'\n",
    "# dataset_file = 'Data/illumination.mat'\n",
    "dataset = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset\n",
    "data_ = sio.loadmat(dataset_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'pose' in dataset_file:\n",
    "    data = data_.get('pose')\n",
    "    dataset = 'pose'\n",
    "elif 'illumination' in dataset_file:\n",
    "    data = data_.get('illum')\n",
    "    dataset = 'illum'\n",
    "else:\n",
    "    data = data_.get('face')\n",
    "    dataset = 'face'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flatten the dataset\n",
    "if dataset == 'pose':\n",
    "    flattened = np.zeros(shape=(subjects*types, data.shape[0]*data.shape[1]))\n",
    "elif dataset == 'illum':\n",
    "    flattened = np.zeros(shape=(subjects*types, data.shape[0]))\n",
    "else:\n",
    "    flattened = np.zeros(shape=(subjects*types, data.shape[0]*data.shape[1]))\n",
    "\n",
    "c = 0\n",
    "d = 0\n",
    "for i in range(flattened.shape[0]):\n",
    "    if c == types:\n",
    "        c = 0\n",
    "        d += 1\n",
    "    if dataset == 'pose':\n",
    "        temp = data[:,:,c,d]\n",
    "        flattened[i] = temp.flatten()\n",
    "    elif dataset == 'face':\n",
    "        temp = data[:,:,i]\n",
    "        flattened[i] = temp.flatten()\n",
    "    elif dataset == 'illum':\n",
    "        flattened[i] = data[:,c,d]\n",
    "    # y[i] = d\n",
    "    c += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def doPCA(flattened, dim):\n",
    "#     pca = PCA(dim)\n",
    "#     projected = pca.fit_transform(flattened)\n",
    "#     return projected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Perform PCA if true\n",
    "# if usePCA:\n",
    "#     pca = PCA().fit(flattened)\n",
    "#     plt.figure()\n",
    "#     plt.xlabel('Dimensions')\n",
    "#     plt.ylabel('Variance Retention')\n",
    "#     plt.plot(pca.explained_variance_ratio_.cumsum(), lw=3)\n",
    "#     min_dim = (np.where(pca.explained_variance_ratio_.cumsum() > 0.95))[0][0]\n",
    "#     print('Minimum dimensions required for 95% retention ', min_dim)\n",
    "#     projected = doPCA(flattened, min_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('Before dimension reduction shape = ', flattened.shape)\n",
    "# print('After dimension reduction shape = ', projected.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'face'"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# noise = {'pose':0.987}\n",
    "noise = {'pose':0.93, 'face':0.999}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98.99456914241867\n",
      "94.65618955191484\n",
      "120.92340485415028\n",
      "244.1201125144308\n",
      "140.92459301001247\n",
      "103.34760701571844\n",
      "137.9865160172802\n",
      "459.1202368593323\n",
      "76.71745911627767\n",
      "75.31896369177547\n",
      "129.33129226194282\n",
      "101.40048176902036\n",
      "176.59874516876792\n",
      "377.03180432903804\n",
      "168.92179270021578\n",
      "108.74583291016359\n",
      "73.95545773577902\n",
      "87.29079347327583\n",
      "85.85010989091364\n",
      "598.7078176112583\n",
      "229.6602309570126\n",
      "129.79773968217677\n",
      "126.13831421147175\n",
      "582.2686249433084\n",
      "214.43416964871693\n",
      "538.7558262921663\n",
      "242.02880016073567\n",
      "77.60257631447878\n",
      "263.4496567746993\n",
      "228.94679039163933\n",
      "203.6300578856702\n",
      "82.68281831112026\n",
      "64.77434774109511\n",
      "181.06247450099366\n",
      "80.00988478964203\n",
      "115.90643547880505\n",
      "167.81755846825496\n",
      "1433.5864425142622\n",
      "470.4138114636537\n",
      "99.20791861671597\n",
      "119.40372800514209\n",
      "240.71895224800974\n",
      "75.05360905122083\n",
      "161.271303887164\n",
      "313.5740187729072\n",
      "208.03207519980285\n",
      "181.46946423589694\n",
      "136.31843920394996\n",
      "51.80265994700934\n",
      "81.56696267397005\n",
      "195.65533588784922\n",
      "237.1402909155222\n",
      "222.07223337956682\n",
      "443.7150359679334\n",
      "371.2919388038934\n",
      "65.40853488215662\n",
      "112.88840245733486\n",
      "107.7760455479884\n",
      "74.99954755007475\n",
      "155.18486370864537\n",
      "248.37851174271384\n",
      "129.0485382256092\n",
      "58.39092329126613\n",
      "77.8596611008912\n",
      "153.8579878048452\n",
      "181.92584518786194\n",
      "115.6623039379238\n",
      "192.83352902553827\n",
      "210.7282157368005\n",
      "125.68444852037655\n",
      "70.6544514371909\n",
      "177.9263284691336\n",
      "200.05111279639019\n",
      "678.9962806433641\n",
      "1883.4660208403159\n",
      "1026.81052396917\n",
      "73.63209361116138\n",
      "208.18188089964747\n",
      "159.65910338903544\n",
      "98.22709042169522\n",
      "156.04219759185398\n",
      "37.29984503529638\n",
      "114.04879084372453\n",
      "218.13866484699008\n",
      "513.5652925198834\n",
      "48.70075862741817\n",
      "129.8149642219621\n",
      "129.996841813316\n",
      "126.52015593775494\n",
      "127.50917193499949\n",
      "177.80490921117558\n",
      "184.30194702837525\n",
      "74.80108090059679\n",
      "172.4598880471298\n",
      "177.95631157510556\n",
      "319.32581919629797\n",
      "224.93417563580203\n",
      "198.96338596866974\n",
      "85.74956456887699\n",
      "1063.829410686524\n",
      "26.17497728268565\n",
      "495.92420425978105\n",
      "119.78214733757456\n",
      "162.81399874154746\n",
      "301.2602279370157\n",
      "303.08358089000825\n",
      "167.60159736535007\n",
      "75.68405114869915\n",
      "81.21116742736402\n",
      "78.50657250428883\n",
      "573.5219802028006\n",
      "191.14936763279616\n",
      "171.1549644833008\n",
      "143.77895927264518\n",
      "252.70365964396055\n",
      "61.04750626653259\n",
      "79.63316377434738\n",
      "345.1232111231823\n",
      "88.89380137345613\n",
      "600.0179031060665\n",
      "116.63507506436662\n",
      "337.9410560221861\n",
      "120.34917314873348\n",
      "75.70760761307686\n",
      "230.04463930776942\n",
      "143.9993947687931\n",
      "645.381785984315\n",
      "454.13005727954214\n",
      "481.6785978728198\n",
      "125.83217705532795\n",
      "246.43543998207858\n",
      "181.84460288785877\n",
      "101.9194795249631\n",
      "49.66856218671263\n",
      "47.56241154932513\n",
      "178.5933651097169\n",
      "109.97986675211692\n",
      "171.5274547879142\n",
      "861.0433861399339\n",
      "139.8283087469372\n",
      "312.9643584744346\n",
      "794.2479673218763\n",
      "77.14149645944605\n",
      "117.46664241497847\n",
      "96.70242364537796\n",
      "171.0303965930192\n",
      "142.6647988427565\n",
      "183.26716027628447\n",
      "71.37616839592036\n",
      "759.5815745279418\n",
      "80.07913201147755\n",
      "95.2711721720325\n",
      "104.43711313636209\n",
      "154.1771416199106\n",
      "1064.6972945632235\n",
      "152.8520510078809\n",
      "497.90192828798644\n",
      "131.43686180486372\n",
      "426.0978425289462\n",
      "535.028966008676\n",
      "411.8979153254064\n",
      "134.0926276355795\n",
      "265.71456553392755\n",
      "455.92321632223064\n",
      "563.5107119552429\n",
      "105.26602370127706\n",
      "48.97666113970001\n",
      "178.01359304025902\n",
      "70.32655337999171\n",
      "170.28645304295736\n",
      "679.2945545931613\n",
      "98.29687376885927\n",
      "101.37801082742949\n",
      "86.33934499315573\n",
      "157.81853878471426\n",
      "1550.2630936664711\n",
      "557.825908331763\n",
      "89.64051619405964\n",
      "76.65580939838527\n",
      "149.76541179413059\n",
      "172.1338110667943\n",
      "171.80674857890207\n",
      "126.54114443236979\n",
      "195.98359932122798\n",
      "88.32006324716733\n",
      "186.5834759008183\n",
      "131.23586123870473\n",
      "548.838900411461\n",
      "374.5722749483832\n",
      "513.6769558751581\n",
      "910.8566530868075\n",
      "459.330033922333\n",
      "81.34381008526076\n",
      "159.52625520084848\n",
      "221.63131331360577\n",
      "135.32762879476613\n",
      "157.5992609824638\n",
      "177.07188029896653\n",
      "227.8726424300323\n",
      "189.20662275318838\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "mu_class = [] # emperical mean of each class\n",
    "cov_class = [] # emperical covariace of each class\n",
    "\n",
    "mu_not = np.zeros(shape=(flattened.shape[1]))\n",
    "sigma_b = np.zeros(shape=(flattened.shape[1], flattened.shape[1]))\n",
    "sigma_w = np.zeros(shape=(flattened.shape[1], flattened.shape[1]))\n",
    "prob = 1/subjects\n",
    "\n",
    "for i in range(subjects):\n",
    "    # determine class as per the data\n",
    "    start = i*types\n",
    "    end = (i+1)*types\n",
    "    # print(start, end)\n",
    "    \n",
    "    temp = flattened[start:end]\n",
    "    mean = np.mean(temp, axis=0)\n",
    "    mu_class.append(mean)\n",
    "\n",
    "    cov = np.zeros(shape=(temp.shape[1], temp.shape[1]))\n",
    "    for k in range(types):\n",
    "        mat = (temp[k] - mean).reshape(temp.shape[1], 1)\n",
    "        cov = cov + np.dot(mat, mat.T)\n",
    "    # mean of covariance\n",
    "    cov = cov / types\n",
    "    # add noise\n",
    "\n",
    "    cov += noise.get(dataset, 0.8)*np.identity(cov.shape[0])\n",
    "    cov_class.append(cov)\n",
    "    print(np.linalg.det(cov))\n",
    "    # break\n",
    "\n",
    "    # emperical mean mu_not\n",
    "    mu_not += prob*mean\n",
    "\n",
    "    #sigma_w\n",
    "    sigma_w += prob*cov\n",
    "\n",
    "# calculate the sigma_b\n",
    "for i in range(subjects):\n",
    "    mat = (mu_class[i] - mu_not).reshape(flattened.shape[1], 1)\n",
    "    sigma_b += prob*np.dot(mat, mat.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25.440157719622196"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # pose   \n",
    "# b = sigma_b + 0.724*np.identity(cov.shape[0])   #0.745999\n",
    "# np.linalg.det(b)\n",
    "\n",
    "# face\n",
    "b = sigma_b + 0.945*np.identity(cov.shape[0])\n",
    "np.linalg.det(b)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = sigma_w #+ np.identity(cov_class[0].shape[0])\n",
    "a = np.dot(np.linalg.inv(sigma_w), b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# for i in range(subjects):\n",
    "#     mat = (mu_class[i] - mu_not).reshape(flattened.shape[1], 1)\n",
    "#     sigma_b += prob*np.dot(mat, mat.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "val, vec = np.linalg.eig(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7.70957982, 4.56649305, 3.57955419, 2.39928485, 2.31974468,\n",
       "       2.12757939, 0.10758501, 1.82186662, 1.76534184, 1.70778498,\n",
       "       1.6014136 , 1.57568863, 0.42685936, 1.50460557, 1.45745142,\n",
       "       1.37983694, 0.61052613, 1.36275052, 1.33597531, 1.3234253 ,\n",
       "       0.64872466, 1.29564514, 1.28050148, 1.25130504, 0.69238929,\n",
       "       1.22486674, 1.22316617, 1.20430274, 1.18299162, 1.17724338,\n",
       "       1.15377782, 1.14645848, 0.74518611, 1.13537888, 0.75269341,\n",
       "       1.11800471, 1.11422122, 1.1081227 , 1.11087304, 1.09885005,\n",
       "       1.09468217, 1.08553592, 1.07950445, 1.07748347, 0.77004629,\n",
       "       0.77519389, 0.77909364, 0.78511493, 0.79190924, 0.79305827,\n",
       "       0.8075819 , 0.81540528, 0.82042677, 0.81695352, 0.81841645,\n",
       "       1.06846564, 1.07152739, 1.05831823, 1.05333209, 0.82390709,\n",
       "       1.05179969, 0.82791803, 0.8313994 , 1.04436604, 1.04361718,\n",
       "       1.04275484, 1.03970693, 0.83921917, 1.03671184, 1.03494042,\n",
       "       0.84060836, 0.84184799, 0.84467707, 1.02967679, 0.85087652,\n",
       "       0.84999953, 1.02615941, 1.02479975, 0.85477256, 1.02223587,\n",
       "       1.01905565, 0.855649  , 0.85775144, 0.85871055, 0.86024475,\n",
       "       1.01562359, 1.01336886, 1.01172152, 1.00879813, 0.86506437,\n",
       "       0.86396703, 1.00667834, 0.86729377, 1.00596059, 0.86860964,\n",
       "       1.00266829, 0.87075249, 1.00115676, 0.87383237, 0.99818041,\n",
       "       1.0002597 , 0.99978362, 0.87705878, 0.87810338, 0.87926243,\n",
       "       0.99468552, 0.88178575, 0.99440461, 0.88233721, 0.99292763,\n",
       "       0.8836795 , 0.88619434, 0.8843813 , 0.88694627, 0.88881391,\n",
       "       0.99164733, 0.88998191, 0.89234693, 0.8939524 , 0.89319774,\n",
       "       0.89091822, 0.98879069, 0.98873238, 0.98696587, 0.98629933,\n",
       "       0.9853176 , 0.98448125, 0.98299924, 0.98275157, 0.98137094,\n",
       "       0.89500322, 0.89529619, 0.89682399, 0.97988697, 0.97850067,\n",
       "       0.97751089, 0.8981867 , 0.97706526, 0.97673509, 0.89870612,\n",
       "       0.9753339 , 0.97638802, 0.97420901, 0.90012866, 0.90086804,\n",
       "       0.97353699, 0.90203555, 0.97187245, 0.97265379, 0.97125618,\n",
       "       0.90364636, 0.90385885, 0.90491618, 0.96947997, 0.96896034,\n",
       "       0.97044991, 0.90501167, 0.9044488 , 0.90590816, 0.90651082,\n",
       "       0.90755429, 0.90934325, 0.90898158, 0.90999396, 0.90881811,\n",
       "       0.91237206, 0.91185414, 0.91118133, 0.91149048, 0.91323493,\n",
       "       0.91334641, 0.91380983, 0.91466827, 0.9144482 , 0.96815516,\n",
       "       0.96783318, 0.96669615, 0.96583484, 0.96534114, 0.96475451,\n",
       "       0.96394946, 0.96391713, 0.96299356, 0.91500287, 0.96289555,\n",
       "       0.96239534, 0.9621432 , 0.91592038, 0.91613467, 0.96158722,\n",
       "       0.96093562, 0.96140363, 0.91694893, 0.91743791, 0.95987367,\n",
       "       0.9180974 , 0.91905427, 0.95836937, 0.95912173, 0.95903782,\n",
       "       0.91946438, 0.92008014, 0.9203347 , 0.92080466, 0.92109445,\n",
       "       0.95831789, 0.92153887, 0.92227163, 0.92245593, 0.92331691,\n",
       "       0.92375715, 0.92171321, 0.92412261, 0.92455531, 0.92439333,\n",
       "       0.95813018, 0.95768717, 0.95764396, 0.95725892, 0.95687191,\n",
       "       0.95623811, 0.95568614, 0.95535098, 0.95498969, 0.92520754,\n",
       "       0.92504184, 0.95464605, 0.95452895, 0.92578949, 0.92590328,\n",
       "       0.92628479, 0.9539251 , 0.92655846, 0.95359135, 0.95297158,\n",
       "       0.92702214, 0.92748509, 0.92773954, 0.92810013, 0.92773402,\n",
       "       0.95274154, 0.92794676, 0.92873995, 0.95259851, 0.95239172,\n",
       "       0.95199259, 0.92928236, 0.92941117, 0.92979736, 0.95179367,\n",
       "       0.95190786, 0.93008265, 0.93079492, 0.93072832, 0.93038052,\n",
       "       0.93032742, 0.93127606, 0.93157138, 0.93203063, 0.95134538,\n",
       "       0.93223991, 0.93230911, 0.95101049, 0.93287263, 0.93259142,\n",
       "       0.93263718, 0.95081307, 0.95083383, 0.95063605, 0.9505928 ,\n",
       "       0.93324067, 0.95027908, 0.95001459, 0.93347192, 0.93363676,\n",
       "       0.94976989, 0.94951587, 0.94928617, 0.93425552, 0.93445645,\n",
       "       0.93478022, 0.94910751, 0.94892553, 0.94879514, 0.94860704,\n",
       "       0.93488035, 0.93500244, 0.94843486, 0.93511153, 0.93534408,\n",
       "       0.94817986, 0.94808441, 0.94799364, 0.94783411, 0.93545215,\n",
       "       0.94791654, 0.93560488, 0.94761438, 0.94729262, 0.94741594,\n",
       "       0.94715252, 0.93581245, 0.9357127 , 0.93623627, 0.93645871,\n",
       "       0.93648126, 0.93657101, 0.93680598, 0.93713436, 0.93723077,\n",
       "       0.94702559, 0.93748135, 0.94693034, 0.94675959, 0.94664765,\n",
       "       0.93761927, 0.93779891, 0.93781061, 0.93809277, 0.93823801,\n",
       "       0.94654814, 0.94641981, 0.94635084, 0.93843554, 0.9461798 ,\n",
       "       0.94610596, 0.93893169, 0.93881234, 0.93868919, 0.946028  ,\n",
       "       0.93909886, 0.94598623, 0.94580624, 0.94568781, 0.94559085,\n",
       "       0.93930341, 0.94552357, 0.94550877, 0.9453789 , 0.93954096,\n",
       "       0.94528409, 0.94594486, 0.94522641, 0.94515737, 0.94512097,\n",
       "       0.9450288 , 0.93970689, 0.9385876 , 0.94471508, 0.94489232,\n",
       "       0.94496633, 0.94492194, 0.94476735, 0.94594595, 0.94594595,\n",
       "       0.94594595, 0.94594595, 0.94594595, 0.93937755, 0.93943218,\n",
       "       0.93974473, 0.93991759, 0.94016649, 0.94034611, 0.94029691,\n",
       "       0.94065437, 0.94004159, 0.94014119, 0.94083473, 0.94048803,\n",
       "       0.94076028, 0.94456077, 0.94449581, 0.94451764, 0.94117153,\n",
       "       0.94441284, 0.94145621, 0.9410912 , 0.94108157, 0.94432489,\n",
       "       0.94429573, 0.94152616, 0.94127337, 0.9418335 , 0.94171946,\n",
       "       0.94166828, 0.94423973, 0.9441692 , 0.94413051, 0.94199885,\n",
       "       0.9420425 , 0.9440833 , 0.94393101, 0.94398348, 0.9421606 ,\n",
       "       0.94218899, 0.94378809, 0.94234939, 0.94376325, 0.94346468,\n",
       "       0.94263598, 0.94241284, 0.94285506, 0.94358171, 0.94300549,\n",
       "       0.94330683, 0.94257601, 0.94306889, 0.94365457, 0.94362658,\n",
       "       0.94252496, 0.94325618, 0.94322551, 0.94244035, 0.94594595,\n",
       "       0.94594595, 0.94594595, 0.94594595, 0.94291422, 0.94314088,\n",
       "       0.94594595, 0.94594595, 0.94594595, 0.94594595, 0.94594595,\n",
       "       0.94594595, 0.94594595, 0.94594595, 0.94594595, 0.94594595,\n",
       "       0.94594595, 0.94594595, 0.94594595, 0.94594595, 0.94594595,\n",
       "       0.94594595, 0.94594595, 0.94594595, 0.94594595, 0.94594595,\n",
       "       0.94594595, 0.94594595, 0.94594595, 0.94594595, 0.94594595,\n",
       "       0.94594595, 0.94594595, 0.94594595, 0.94594595, 0.94594595,\n",
       "       0.94594595, 0.94594595, 0.94594595, 0.94594595, 0.94594595,\n",
       "       0.94594595, 0.94594595, 0.94594595, 0.94594595, 0.94594595,\n",
       "       0.94594595, 0.94594595, 0.94594595, 0.94594595, 0.94594595,\n",
       "       0.94594595, 0.94594595, 0.94594595, 0.94594595, 0.94594595,\n",
       "       0.94594595, 0.94594595, 0.94594595, 0.94594595, 0.94594595,\n",
       "       0.94594595, 0.94594595, 0.94594595, 0.94594595, 0.94594595,\n",
       "       0.94594595, 0.94594595, 0.94594595, 0.94594595, 0.94594595,\n",
       "       0.94594595, 0.94594595, 0.94594595, 0.94594595, 0.94594595,\n",
       "       0.94594595, 0.94594595, 0.94594595, 0.94594595, 0.94594595,\n",
       "       0.94594595, 0.94594595, 0.94594595, 0.94594595, 0.94594595,\n",
       "       0.94594595, 0.94594595, 0.94594595, 0.94594595])"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(423145.6879954041+0j)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3.57757839e-02, -3.24453189e-02,  2.29604262e-02, -3.96572935e-02,\n",
       "        3.97997267e-03, -1.45317922e-02, -2.43322378e-02, -1.94980155e-02,\n",
       "       -3.59646127e-02,  2.19187500e-02,  3.49526548e-03,  1.37735149e-02,\n",
       "        8.19477500e-03, -1.49545961e-02,  5.53344639e-04, -2.36803094e-02,\n",
       "       -4.21063535e-03,  3.30439023e-04, -1.01662682e-02,  1.32883087e-02,\n",
       "        8.10518176e-03,  1.91207559e-02, -3.36824364e-02, -6.87866920e-03,\n",
       "        9.94912154e-03,  2.38346738e-02, -9.94525342e-03, -1.19204369e-02,\n",
       "        7.81709490e-03,  1.06855609e-02,  6.28964099e-03,  2.00766609e-03,\n",
       "        4.70701850e-04, -1.70269486e-02, -5.86230578e-03,  7.91888392e-04,\n",
       "        4.65040683e-03,  8.66268415e-03,  2.84591003e-03,  1.53082669e-02,\n",
       "       -2.41889228e-03, -5.10779819e-03, -1.72193251e-02, -9.53942225e-03,\n",
       "       -9.46535446e-03,  1.64128859e-03, -1.28145428e-02,  2.58085390e-02,\n",
       "        3.55591111e-03, -1.11265042e-02,  1.89597025e-02,  1.69810422e-02,\n",
       "       -4.23988358e-03, -4.38364271e-03, -1.84576462e-03,  1.00300857e-02,\n",
       "        6.50925826e-04,  3.42687186e-03,  1.54144939e-02,  6.98394296e-03,\n",
       "       -1.00071481e-02, -1.18674828e-02, -7.49302344e-03,  2.23258067e-02,\n",
       "        5.86085944e-03,  1.56276902e-04, -3.59125757e-03,  5.99916188e-03,\n",
       "        1.02875637e-02, -4.91351422e-03, -4.78834269e-03,  8.29278297e-03,\n",
       "        6.41676500e-03, -6.41805864e-03,  8.88897292e-03,  4.43306272e-05,\n",
       "       -1.74918664e-02, -1.25530167e-02,  1.75806187e-02,  1.05884867e-03,\n",
       "       -4.51955911e-03,  1.28200296e-03,  6.42786155e-03,  1.72196226e-03,\n",
       "       -1.90307067e-03,  8.29850708e-03, -1.65812530e-03, -3.16793298e-03,\n",
       "        2.44189379e-02, -1.33029732e-02,  1.20929052e-03,  6.85582138e-03,\n",
       "        6.46617389e-03, -4.16033509e-03,  4.56627691e-03,  1.26366131e-02,\n",
       "        7.76153609e-04, -8.05195181e-03, -2.62074375e-03,  1.63518309e-02,\n",
       "       -1.82477610e-02,  2.32857014e-03,  3.49784527e-03, -3.97678049e-03,\n",
       "       -2.12077491e-03, -1.67285524e-02, -7.92499040e-03, -9.41257976e-03,\n",
       "        4.79575366e-03,  9.60414426e-03, -1.21299205e-03, -7.90577078e-03,\n",
       "        1.86340606e-02, -7.99101514e-03,  1.30097426e-02,  4.87774499e-05,\n",
       "        7.90070673e-03,  8.58973694e-03, -1.35046910e-02,  7.65707397e-03,\n",
       "       -1.86407873e-04, -5.94658966e-03, -6.50460533e-03, -3.33468485e-02,\n",
       "       -1.16849046e-02,  5.85344207e-05, -4.14477987e-03,  1.70370994e-02,\n",
       "        1.66764097e-02,  1.20762484e-02,  4.16576725e-03,  4.13647921e-03,\n",
       "       -5.53739911e-03,  5.83924237e-03,  7.25182787e-03,  2.62687487e-02,\n",
       "       -8.44258706e-03, -9.61671738e-03,  2.09704774e-02, -4.57443951e-03,\n",
       "        1.96190538e-02,  2.91363943e-04,  1.56689036e-02, -2.34831155e-03,\n",
       "       -7.70353953e-03,  1.65676043e-02,  2.74753126e-03,  4.07614206e-02,\n",
       "        1.29862992e-04, -1.20492212e-02, -6.94272580e-03, -2.64066408e-03,\n",
       "       -1.59761126e-02,  3.88676780e-03, -4.15452954e-03,  1.79124790e-03,\n",
       "        7.67391965e-03,  1.41228637e-04,  3.48464110e-03,  4.64563694e-04,\n",
       "        9.56286215e-04,  1.43964302e-02, -9.78070669e-03, -4.56556760e-03,\n",
       "       -1.07254495e-03, -1.89612328e-02,  1.80227620e-02, -1.93710774e-02,\n",
       "       -6.72226996e-03,  1.51085698e-02, -8.03100075e-03, -6.20117108e-03,\n",
       "        1.20931842e-02, -3.28000072e-03,  1.80927910e-02, -9.29479096e-03,\n",
       "       -1.65028264e-02,  4.15664628e-02, -3.66440911e-02, -1.35097933e-02,\n",
       "       -3.57218861e-02, -9.36546446e-03, -3.59360859e-02,  1.02545290e-02,\n",
       "        1.44410926e-02, -2.56090564e-03, -4.32592010e-02,  7.65634360e-03,\n",
       "        7.68226601e-03,  2.29122329e-02,  3.90536425e-02,  1.55698494e-02,\n",
       "       -1.48910258e-02, -9.18384025e-03, -3.21029246e-02, -1.67934865e-02,\n",
       "       -1.33288982e-02, -3.63176127e-02,  9.94210469e-03,  1.18476716e-02,\n",
       "        8.93166340e-03, -2.12356876e-03,  1.91115376e-02, -1.14092507e-02,\n",
       "       -3.74932630e-03,  1.98639930e-03,  5.30552623e-03, -1.13179522e-02,\n",
       "        1.82102192e-02, -5.74423082e-03, -1.27271214e-02,  3.67057075e-03,\n",
       "       -8.08198817e-03, -6.92353315e-03, -9.09737509e-04,  2.39620387e-03,\n",
       "       -1.91140928e-02,  1.37818691e-02,  2.84542830e-02,  2.28134989e-02,\n",
       "        1.59086471e-02,  2.59462799e-02, -6.22840406e-03,  1.97167859e-02,\n",
       "       -8.91561904e-03, -7.39374654e-04,  2.14425057e-02, -5.75790995e-03,\n",
       "       -6.76558023e-03, -1.44836770e-02,  3.36690869e-03,  3.81390903e-02,\n",
       "        2.09058265e-03,  1.89191496e-03,  4.32946436e-02,  8.94280913e-03,\n",
       "       -2.13461488e-02, -1.85106767e-02, -7.66953828e-03,  2.68137645e-03,\n",
       "        1.31956539e-02,  9.80723332e-04,  1.26375182e-02, -1.34691026e-02,\n",
       "       -6.17938241e-03, -6.61966890e-02,  1.63765400e-02,  8.45413055e-03,\n",
       "        9.12674048e-03,  5.73632541e-02, -2.64531460e-02,  1.44145751e-02,\n",
       "        9.23997972e-03,  5.87625382e-03,  9.24201857e-03, -2.88668636e-03,\n",
       "        4.65394954e-03, -1.09869982e-02, -1.28126169e-02,  9.80847592e-03,\n",
       "       -3.02908094e-02, -1.19595452e-02,  7.51700580e-02, -1.45297258e-02,\n",
       "        4.29901893e-03,  5.07927524e-03,  7.34223088e-02,  3.19349711e-02,\n",
       "        2.71800947e-02,  4.55799292e-03, -5.92731102e-03, -1.26699082e-02,\n",
       "       -4.09624505e-02,  5.75293864e-03,  2.02429158e-02,  8.41821519e-02,\n",
       "        1.65065248e-01,  5.21304974e-02,  6.25208260e-03, -6.73723927e-03,\n",
       "       -5.62396264e-03, -1.17224500e-02,  4.64953547e-02,  4.30633541e-02,\n",
       "       -1.56304892e-01, -1.17063894e-02,  3.15095996e-02, -8.20352258e-02,\n",
       "        1.72492774e-02,  1.00128854e-02, -4.39396731e-02, -5.22108587e-02,\n",
       "        3.47221502e-02, -7.49111176e-02,  1.05528495e-02, -2.71487596e-02,\n",
       "       -3.60545190e-02,  1.19971198e-01,  1.13078542e-01, -2.53550354e-02,\n",
       "        1.32470052e-01,  5.20270975e-03, -2.01211057e-03,  1.32855514e-02,\n",
       "       -1.97155907e-02, -2.18613661e-02, -4.75723289e-03, -1.82472328e-02,\n",
       "       -1.49623388e-03, -8.81650517e-03, -7.75951328e-02,  2.26931314e-02,\n",
       "        2.49804630e-01,  3.57357819e-02, -2.19093928e-01,  3.49092808e-03,\n",
       "        7.53014806e-03,  1.11906421e-02, -1.13761227e-02,  1.58698809e-02,\n",
       "        1.52010318e-03,  1.92291196e-02, -1.91066255e-01, -2.24721113e-02,\n",
       "        2.39109279e-01,  1.54824308e-01, -2.95408470e-02,  3.27286734e-02,\n",
       "       -7.95690717e-03, -2.43512330e-01, -2.06394652e-02, -1.17234493e-01,\n",
       "       -5.29282718e-02, -2.17569818e-01, -2.57064037e-01,  3.41898559e-02,\n",
       "       -2.26047710e-01,  6.96558623e-02, -3.82587943e-02, -2.87543064e-02,\n",
       "        1.29720586e-01, -1.85945964e-01,  1.14997072e-01, -1.40424206e-01,\n",
       "       -5.44944207e-02,  2.03562736e-02,  4.54882983e-02, -2.52671068e-04,\n",
       "        1.85815727e-01,  1.09229631e-01,  4.84068860e-02,  7.26447288e-02,\n",
       "       -1.04471124e-01, -2.16548351e-03, -4.37936351e-02,  2.64342533e-03,\n",
       "       -8.40504305e-04, -1.63709064e-04, -9.08014306e-03,  6.41213707e-03,\n",
       "        2.27892628e-02,  3.49981982e-03, -3.63034840e-02, -3.51445225e-02,\n",
       "        3.05992502e-02, -3.66226841e-02, -4.45043197e-03, -1.68048517e-02,\n",
       "        3.32309841e-02, -1.14899748e-02,  1.37317829e-02,  9.68208178e-02,\n",
       "        1.11147921e-01,  4.55662813e-02, -2.09205225e-02,  1.26307971e-02,\n",
       "       -5.06819912e-02,  4.29971004e-02, -1.87764734e-02,  1.29908883e-01,\n",
       "        3.67369589e-02,  1.53680152e-02, -1.86751545e-04, -5.44817328e-02,\n",
       "       -2.30138393e-02,  1.16124466e-02, -8.42890261e-02, -6.66709548e-02,\n",
       "       -1.29074975e-01,  3.79751874e-02,  4.86123411e-02,  7.74985641e-02,\n",
       "       -6.36931540e-02, -6.13443811e-03,  4.03145134e-02,  1.65893572e-02,\n",
       "       -2.57838506e-02,  7.45365041e-03, -2.44471123e-02,  5.81715276e-02,\n",
       "        4.44354088e-02, -4.76785963e-02, -2.88250202e-02,  4.38390439e-02,\n",
       "       -1.03624765e-01,  5.17629709e-02,  7.11257859e-02,  5.88223124e-02,\n",
       "       -2.47154346e-02,  2.10490985e-02, -1.25661493e-02, -5.84666461e-02,\n",
       "        7.10596904e-02,  5.50446356e-03, -1.93812902e-04, -1.02048241e-02,\n",
       "        3.07529536e-03,  2.90158026e-03, -1.04578771e-03,  3.20633098e-03,\n",
       "        2.19048319e-04, -2.52709364e-03,  9.39941714e-04,  2.43856259e-04,\n",
       "       -6.51822886e-04,  1.54885059e-03, -4.00464979e-04, -2.89213861e-03,\n",
       "       -9.09512962e-04, -9.03487778e-04, -8.71507125e-04, -1.72539642e-03,\n",
       "       -3.42599072e-03, -5.78226276e-03, -5.16681755e-04, -5.71596612e-04,\n",
       "       -3.22945978e-04,  2.22765083e-04, -3.08538174e-04, -2.32558280e-03,\n",
       "       -7.18026912e-04,  1.01700351e-04,  4.94760396e-03, -1.27688734e-03,\n",
       "        5.47452575e-04, -1.23152741e-04,  1.74047024e-03, -7.16669544e-03,\n",
       "        8.97246550e-04, -3.41187935e-04, -1.81387622e-03,  8.75880839e-04,\n",
       "       -4.35740838e-04,  4.02628390e-03, -5.02909768e-03,  4.02861255e-03,\n",
       "        4.81191017e-04,  1.31892144e-03, -1.55414836e-04,  1.15076213e-04,\n",
       "        4.89498130e-04,  8.26210928e-04, -6.33563627e-05, -1.80377844e-03,\n",
       "       -1.49911242e-04,  7.67659034e-04,  4.33864677e-04,  1.56330391e-04,\n",
       "        1.75177325e-03, -7.72905050e-04,  7.43105071e-04,  3.17595573e-04,\n",
       "        1.99818467e-06,  9.59843501e-04,  9.77661266e-04, -1.56935104e-03,\n",
       "        1.64957257e-03, -2.39152784e-04,  1.37901163e-03,  6.65414346e-04,\n",
       "       -2.23802318e-03,  5.66584622e-04,  5.25584298e-04,  2.26992567e-03,\n",
       "       -3.31367592e-04, -1.82156191e-03,  1.29067930e-03,  8.80965253e-04,\n",
       "       -4.90484595e-04, -2.13087618e-03,  6.54027765e-04,  5.46347805e-04,\n",
       "       -1.39773927e-04,  1.02719616e-03, -1.17700456e-03,  1.97821859e-03,\n",
       "        2.89904995e-03, -1.70922097e-03, -1.20419004e-03, -1.39956710e-03,\n",
       "       -1.24185907e-03, -2.23477428e-04,  7.02697799e-04,  2.28902558e-04])"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import  LinearDiscriminantAnalysis\n",
    "lda = LinearDiscriminantAnalysis(solver='eigen')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = lda.fit(flattened, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(lda.explained_variance_ratio_.cumsum(), lw=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = lda.fit_transform(flattened, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = val.argsort()[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7.70957982, 4.56649305, 3.57955419, 2.39928485, 2.31974468,\n",
       "       2.12757939, 1.82186662, 1.76534184, 1.70778498, 1.6014136 ,\n",
       "       1.57568863, 1.50460557, 1.45745142, 1.37983694, 1.36275052,\n",
       "       1.33597531, 1.3234253 , 1.29564514, 1.28050148, 1.25130504,\n",
       "       1.22486674, 1.22316617, 1.20430274, 1.18299162, 1.17724338,\n",
       "       1.15377782, 1.14645848, 1.13537888, 1.11800471, 1.11422122,\n",
       "       1.11087304, 1.1081227 , 1.09885005, 1.09468217, 1.08553592,\n",
       "       1.07950445, 1.07748347, 1.07152739, 1.06846564, 1.05831823,\n",
       "       1.05333209, 1.05179969, 1.04436604, 1.04361718, 1.04275484,\n",
       "       1.03970693, 1.03671184, 1.03494042, 1.02967679, 1.02615941,\n",
       "       1.02479975, 1.02223587, 1.01905565, 1.01562359, 1.01336886,\n",
       "       1.01172152, 1.00879813, 1.00667834, 1.00596059, 1.00266829,\n",
       "       1.00115676, 1.0002597 , 0.99978362, 0.99818041, 0.99468552,\n",
       "       0.99440461, 0.99292763, 0.99164733, 0.98879069, 0.98873238,\n",
       "       0.98696587, 0.98629933, 0.9853176 , 0.98448125, 0.98299924,\n",
       "       0.98275157, 0.98137094, 0.97988697, 0.97850067, 0.97751089,\n",
       "       0.97706526, 0.97673509, 0.97638802, 0.9753339 , 0.97420901,\n",
       "       0.97353699, 0.97265379, 0.97187245, 0.97125618, 0.97044991,\n",
       "       0.96947997, 0.96896034, 0.96815516, 0.96783318, 0.96669615,\n",
       "       0.96583484, 0.96534114, 0.96475451, 0.96394946, 0.96391713,\n",
       "       0.96299356, 0.96289555, 0.96239534, 0.9621432 , 0.96158722,\n",
       "       0.96140363, 0.96093562, 0.95987367, 0.95912173, 0.95903782,\n",
       "       0.95836937, 0.95831789, 0.95813018, 0.95768717, 0.95764396,\n",
       "       0.95725892, 0.95687191, 0.95623811, 0.95568614, 0.95535098,\n",
       "       0.95498969, 0.95464605, 0.95452895, 0.9539251 , 0.95359135,\n",
       "       0.95297158, 0.95274154, 0.95259851, 0.95239172, 0.95199259,\n",
       "       0.95190786, 0.95179367, 0.95134538, 0.95101049, 0.95083383,\n",
       "       0.95081307, 0.95063605, 0.9505928 , 0.95027908, 0.95001459,\n",
       "       0.94976989, 0.94951587, 0.94928617, 0.94910751, 0.94892553,\n",
       "       0.94879514, 0.94860704, 0.94843486, 0.94817986, 0.94808441,\n",
       "       0.94799364, 0.94791654, 0.94783411, 0.94761438, 0.94741594,\n",
       "       0.94729262, 0.94715252, 0.94702559, 0.94693034, 0.94675959,\n",
       "       0.94664765, 0.94654814, 0.94641981, 0.94635084, 0.9461798 ,\n",
       "       0.94610596, 0.946028  , 0.94598623, 0.94594595, 0.94594595,\n",
       "       0.94594595, 0.94594595, 0.94594595, 0.94594595, 0.94594595,\n",
       "       0.94594595, 0.94594595, 0.94594595, 0.94594595, 0.94594595,\n",
       "       0.94594595, 0.94594595, 0.94594595, 0.94594595, 0.94594595,\n",
       "       0.94594595, 0.94594595, 0.94594595, 0.94594595, 0.94594595,\n",
       "       0.94594595, 0.94594595, 0.94594595, 0.94594595, 0.94594595,\n",
       "       0.94594595, 0.94594595, 0.94594595, 0.94594595, 0.94594595,\n",
       "       0.94594595, 0.94594595, 0.94594595, 0.94594595, 0.94594595,\n",
       "       0.94594595, 0.94594595, 0.94594595, 0.94594595, 0.94594595,\n",
       "       0.94594595, 0.94594595, 0.94594595, 0.94594595, 0.94594595,\n",
       "       0.94594595, 0.94594595, 0.94594595, 0.94594595, 0.94594595,\n",
       "       0.94594595, 0.94594595, 0.94594595, 0.94594595, 0.94594595,\n",
       "       0.94594595, 0.94594595, 0.94594595, 0.94594595, 0.94594595,\n",
       "       0.94594595, 0.94594595, 0.94594595, 0.94594595, 0.94594595,\n",
       "       0.94594595, 0.94594595, 0.94594595, 0.94594595, 0.94594595,\n",
       "       0.94594595, 0.94594595, 0.94594595, 0.94594595, 0.94594595,\n",
       "       0.94594595, 0.94594595, 0.94594595, 0.94594595, 0.94594595,\n",
       "       0.94594595, 0.94594595, 0.94594595, 0.94594595, 0.94594595,\n",
       "       0.94594595, 0.94594595, 0.94594595, 0.94594595, 0.94594595,\n",
       "       0.94594595, 0.94594486, 0.94580624, 0.94568781, 0.94559085,\n",
       "       0.94552357, 0.94550877, 0.9453789 , 0.94528409, 0.94522641,\n",
       "       0.94515737, 0.94512097, 0.9450288 , 0.94496633, 0.94492194,\n",
       "       0.94489232, 0.94476735, 0.94471508, 0.94456077, 0.94451764,\n",
       "       0.94449581, 0.94441284, 0.94432489, 0.94429573, 0.94423973,\n",
       "       0.9441692 , 0.94413051, 0.9440833 , 0.94398348, 0.94393101,\n",
       "       0.94378809, 0.94376325, 0.94365457, 0.94362658, 0.94358171,\n",
       "       0.94346468, 0.94330683, 0.94325618, 0.94322551, 0.94314088,\n",
       "       0.94306889, 0.94300549, 0.94291422, 0.94285506, 0.94263598,\n",
       "       0.94257601, 0.94252496, 0.94244035, 0.94241284, 0.94234939,\n",
       "       0.94218899, 0.9421606 , 0.9420425 , 0.94199885, 0.9418335 ,\n",
       "       0.94171946, 0.94166828, 0.94152616, 0.94145621, 0.94127337,\n",
       "       0.94117153, 0.9410912 , 0.94108157, 0.94083473, 0.94076028,\n",
       "       0.94065437, 0.94048803, 0.94034611, 0.94029691, 0.94016649,\n",
       "       0.94014119, 0.94004159, 0.93991759, 0.93974473, 0.93970689,\n",
       "       0.93954096, 0.93943218, 0.93937755, 0.93930341, 0.93909886,\n",
       "       0.93893169, 0.93881234, 0.93868919, 0.9385876 , 0.93843554,\n",
       "       0.93823801, 0.93809277, 0.93781061, 0.93779891, 0.93761927,\n",
       "       0.93748135, 0.93723077, 0.93713436, 0.93680598, 0.93657101,\n",
       "       0.93648126, 0.93645871, 0.93623627, 0.93581245, 0.9357127 ,\n",
       "       0.93560488, 0.93545215, 0.93534408, 0.93511153, 0.93500244,\n",
       "       0.93488035, 0.93478022, 0.93445645, 0.93425552, 0.93363676,\n",
       "       0.93347192, 0.93324067, 0.93287263, 0.93263718, 0.93259142,\n",
       "       0.93230911, 0.93223991, 0.93203063, 0.93157138, 0.93127606,\n",
       "       0.93079492, 0.93072832, 0.93038052, 0.93032742, 0.93008265,\n",
       "       0.92979736, 0.92941117, 0.92928236, 0.92873995, 0.92810013,\n",
       "       0.92794676, 0.92773954, 0.92773402, 0.92748509, 0.92702214,\n",
       "       0.92655846, 0.92628479, 0.92590328, 0.92578949, 0.92520754,\n",
       "       0.92504184, 0.92455531, 0.92439333, 0.92412261, 0.92375715,\n",
       "       0.92331691, 0.92245593, 0.92227163, 0.92171321, 0.92153887,\n",
       "       0.92109445, 0.92080466, 0.9203347 , 0.92008014, 0.91946438,\n",
       "       0.91905427, 0.9180974 , 0.91743791, 0.91694893, 0.91613467,\n",
       "       0.91592038, 0.91500287, 0.91466827, 0.9144482 , 0.91380983,\n",
       "       0.91334641, 0.91323493, 0.91237206, 0.91185414, 0.91149048,\n",
       "       0.91118133, 0.90999396, 0.90934325, 0.90898158, 0.90881811,\n",
       "       0.90755429, 0.90651082, 0.90590816, 0.90501167, 0.90491618,\n",
       "       0.9044488 , 0.90385885, 0.90364636, 0.90203555, 0.90086804,\n",
       "       0.90012866, 0.89870612, 0.8981867 , 0.89682399, 0.89529619,\n",
       "       0.89500322, 0.8939524 , 0.89319774, 0.89234693, 0.89091822,\n",
       "       0.88998191, 0.88881391, 0.88694627, 0.88619434, 0.8843813 ,\n",
       "       0.8836795 , 0.88233721, 0.88178575, 0.87926243, 0.87810338,\n",
       "       0.87705878, 0.87383237, 0.87075249, 0.86860964, 0.86729377,\n",
       "       0.86506437, 0.86396703, 0.86024475, 0.85871055, 0.85775144,\n",
       "       0.855649  , 0.85477256, 0.85087652, 0.84999953, 0.84467707,\n",
       "       0.84184799, 0.84060836, 0.83921917, 0.8313994 , 0.82791803,\n",
       "       0.82390709, 0.82042677, 0.81841645, 0.81695352, 0.81540528,\n",
       "       0.8075819 , 0.79305827, 0.79190924, 0.78511493, 0.77909364,\n",
       "       0.77519389, 0.77004629, 0.75269341, 0.74518611, 0.69238929,\n",
       "       0.64872466, 0.61052613, 0.42685936, 0.10758501])"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_ = val[idx]\n",
    "val_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_  = vec[:, idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(504, 504)"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = 199\n",
    "vec__ = vec_[:,:dim]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(504, 199)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec__.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = np.dot(flattened, vec__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST ON FACE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "projected = f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(600, 199)"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "projected.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24, 21, 600)"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "useMDA = True\n",
    "if (useMDA):\n",
    "    training_data = []\n",
    "    testing_data = []\n",
    "    c = 1 # counter to pick random sample from either illumination or \n",
    "    for i in range(0, data.shape[2], 3):\n",
    "        training_data.append(projected[i])\n",
    "        if c % 2 == 0:\n",
    "            training_data.append(projected[i+1])\n",
    "            testing_data.append(projected[i+2])\n",
    "        else:\n",
    "            training_data.append(projected[i+2])\n",
    "            testing_data.append(projected[i+1])\n",
    "        c += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.649379822361784\n",
      "3.6145086456934328\n",
      "9.149803066954837\n",
      "6.793423542608418\n",
      "5.127702178287167\n",
      "4.038220327909681\n",
      "6.062699150384918\n",
      "4.324983912189782\n",
      "5.326610993142969\n",
      "2.9110140356356697\n",
      "7.409180287333318\n",
      "5.367608435455189\n",
      "7.816695848654923\n",
      "8.786732815635073\n",
      "7.748799414515975\n",
      "4.602547160738278\n",
      "5.994280203758261\n",
      "2.8125514045702427\n",
      "4.296643032596023\n",
      "6.55203882057608\n",
      "9.501115273789779\n",
      "3.398748972203964\n",
      "4.538254803134906\n",
      "5.195700020086381\n",
      "4.277718547329315\n",
      "7.133609180203286\n",
      "4.966321420733529\n",
      "3.686942616020682\n",
      "10.035068412627131\n",
      "4.274837197684763\n",
      "3.877599810080514\n",
      "4.144939749421682\n",
      "5.656129614150467\n",
      "3.6692938469324323\n",
      "6.239349160538938\n",
      "3.9497503601998547\n",
      "3.8796624886575275\n",
      "8.215539760538553\n",
      "9.415507707324318\n",
      "4.412448781843359\n",
      "4.2468908597372526\n",
      "4.799430189932512\n",
      "4.4901435834617285\n",
      "4.488853831198663\n",
      "10.723549694160436\n",
      "10.987655416191009\n",
      "7.0729574341624355\n",
      "6.197447086825862\n",
      "4.124455902203039\n",
      "3.6239580263236952\n",
      "6.776948681129207\n",
      "7.981544274300526\n",
      "5.394416455010537\n",
      "8.520604873823439\n",
      "8.545057146781014\n",
      "2.6723713062836514\n",
      "5.51079182254197\n",
      "4.970799711862871\n",
      "4.536109716244049\n",
      "4.636672014057792\n",
      "7.090276985598178\n",
      "4.41484511346688\n",
      "3.8180420494929344\n",
      "3.919966939852023\n",
      "8.160905163922976\n",
      "5.72779148937122\n",
      "6.814359533024994\n",
      "4.481589301473309\n",
      "4.638232456667147\n",
      "3.2504690806464263\n",
      "4.597621304948612\n",
      "9.18276307852937\n",
      "6.34478171784691\n",
      "12.048566458618838\n",
      "9.135409736400502\n",
      "11.50005433592487\n",
      "5.435836515556119\n",
      "6.809224674188152\n",
      "10.247832245593571\n",
      "4.635147408221768\n",
      "4.096639171627323\n",
      "2.1758176467807564\n",
      "4.201310249824561\n",
      "5.159256787501273\n",
      "5.695389618606573\n",
      "2.6866726416852615\n",
      "8.535795279452634\n",
      "6.110539835271994\n",
      "5.2462787766628525\n",
      "3.3440721007024177\n",
      "4.419830221274298\n",
      "3.9135031764540686\n",
      "3.064304778000734\n",
      "7.120202413523424\n",
      "4.8853330244877355\n",
      "7.502604703718063\n",
      "5.310486313255463\n",
      "4.769377128251341\n",
      "3.1570247611935134\n",
      "10.483234612046706\n",
      "4.617646893525462\n",
      "12.090347500841716\n",
      "5.638540235831278\n",
      "2.9740874387738434\n",
      "6.101542974390936\n",
      "9.060267693175565\n",
      "4.394008054278999\n",
      "5.0617701045368015\n",
      "3.078998806292891\n",
      "5.001886229125924\n",
      "9.162717522006574\n",
      "6.435130976631443\n",
      "7.605762612720603\n",
      "5.184074324333421\n",
      "3.5825182659047523\n",
      "2.78900365781411\n",
      "4.152694324785463\n",
      "5.0241193894162794\n",
      "4.214613147307264\n",
      "7.30015135078203\n",
      "3.5837156696319603\n",
      "8.668659339279841\n",
      "4.850196271584634\n",
      "2.9223712414954286\n",
      "5.1045077864084\n",
      "7.42321129884246\n",
      "12.157768733791732\n",
      "4.7714520474896585\n",
      "5.359025590136623\n",
      "5.461424803850855\n",
      "13.87342617177019\n",
      "4.08638542319653\n",
      "3.47349641129967\n",
      "2.51147443537008\n",
      "4.5362375855938994\n",
      "11.009848761314512\n",
      "5.013738254585073\n",
      "6.1340667077494695\n",
      "6.468639348690037\n",
      "4.281465545535332\n",
      "9.376061397467891\n",
      "8.43013713089992\n",
      "3.422242663556724\n",
      "4.385701289155641\n",
      "4.862304656201117\n",
      "3.916484430613138\n",
      "3.5035683452755584\n",
      "4.557258644801256\n",
      "4.935935769272476\n",
      "16.243137510461377\n",
      "4.477794670168581\n",
      "4.232049513141335\n",
      "3.0463641949814946\n",
      "3.7018692760815526\n",
      "7.152956816881208\n",
      "6.690481509116616\n",
      "7.137548033338252\n",
      "5.909478646059994\n",
      "4.811546377405285\n",
      "5.372791484644053\n",
      "12.331143614917185\n",
      "5.307222948892394\n",
      "11.130837522125875\n",
      "7.134756131826287\n",
      "5.093772378175348\n",
      "3.5471787293719426\n",
      "3.8157995957215554\n",
      "7.917622153082717\n",
      "5.70249011506323\n",
      "8.102507538501321\n",
      "10.816222260314401\n",
      "4.107304045287201\n",
      "5.909047857745745\n",
      "3.20028447925583\n",
      "6.635424569108195\n",
      "25.684592108600235\n",
      "5.6451608497445305\n",
      "4.419774467010022\n",
      "3.0666485085613395\n",
      "5.30966678876222\n",
      "4.2203237555582245\n",
      "4.105196837084412\n",
      "5.271464222008118\n",
      "5.98061691464294\n",
      "5.493589846387262\n",
      "5.38297275494368\n",
      "4.363333782107539\n",
      "8.31610921551074\n",
      "6.803529774312635\n",
      "5.208156556656743\n",
      "19.274725060086826\n",
      "7.393995074443319\n",
      "2.884548507588252\n",
      "8.776085468733458\n",
      "5.499046863642419\n",
      "4.7477269386189915\n",
      "4.048442346003295\n",
      "8.74567605192361\n",
      "8.05819775795907\n",
      "4.796228965315482\n"
     ]
    }
   ],
   "source": [
    "if(useMDA):\n",
    "    mu = []\n",
    "    cov = []\n",
    "    for i in range(0, len(training_data), 2):\n",
    "        mean = ((training_data[i] + training_data[i+1]) / 2).reshape(1, projected.shape[1])\n",
    "        cov1 = np.matmul((training_data[i]-mean).T, training_data[i]-mean)\n",
    "        cov2 = np.matmul((training_data[i+1]-mean).T, training_data[i+1]-mean)\n",
    "        noise = 1.0*np.identity(cov1.shape[0]) #0.24\n",
    "        cov_ = (cov1 + cov2)/2 + noise\n",
    "        print(np.linalg.det(cov_))\n",
    "        # break\n",
    "        cov.append(cov_)\n",
    "        mu.append(mean)\n",
    "        if np.linalg.det(cov_) == 0 or np.linalg.det(cov_) == 0.0:\n",
    "            print('alert - zero determinant')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct, score is now  1\n",
      "Correct, score is now  2\n",
      "Correct, score is now  3\n",
      "Correct, score is now  4\n",
      "Correct, score is now  5\n",
      "Correct, score is now  6\n",
      "Correct, score is now  7\n",
      "Correct, score is now  8\n",
      "Correct, score is now  9\n",
      "Correct, score is now  10\n",
      "Correct, score is now  11\n",
      "Correct, score is now  12\n",
      "Correct, score is now  13\n",
      "Correct, score is now  14\n",
      "Correct, score is now  15\n",
      "Correct, score is now  16\n",
      "Correct, score is now  17\n",
      "Correct, score is now  18\n",
      "Correct, score is now  19\n",
      "Correct, score is now  20\n",
      "Correct, score is now  21\n",
      "Correct, score is now  22\n",
      "Correct, score is now  23\n",
      "Correct, score is now  24\n",
      "Correct, score is now  25\n",
      "Correct, score is now  26\n",
      "Correct, score is now  27\n",
      "Correct, score is now  28\n",
      "Correct, score is now  29\n",
      "Correct, score is now  30\n",
      "Correct, score is now  31\n",
      "Correct, score is now  32\n",
      "Correct, score is now  33\n",
      "Correct, score is now  34\n",
      "Correct, score is now  35\n",
      "Correct, score is now  36\n",
      "Correct, score is now  37\n",
      "Correct, score is now  38\n",
      "Correct, score is now  39\n",
      "Correct, score is now  40\n",
      "Correct, score is now  41\n",
      "Correct, score is now  42\n",
      "Correct, score is now  43\n",
      "Correct, score is now  44\n",
      "Correct, score is now  45\n",
      "Correct, score is now  46\n",
      "Correct, score is now  47\n",
      "Correct, score is now  48\n",
      "Correct, score is now  49\n",
      "Correct, score is now  50\n",
      "Correct, score is now  51\n",
      "Correct, score is now  52\n",
      "Correct, score is now  53\n",
      "Correct, score is now  54\n",
      "Correct, score is now  55\n",
      "Correct, score is now  56\n",
      "Correct, score is now  57\n",
      "Correct, score is now  58\n",
      "Correct, score is now  59\n",
      "Correct, score is now  60\n",
      "Correct, score is now  61\n",
      "Correct, score is now  62\n",
      "Correct, score is now  63\n",
      "Correct, score is now  64\n",
      "Correct, score is now  65\n",
      "Correct, score is now  66\n",
      "Correct, score is now  67\n",
      "Correct, score is now  68\n",
      "Correct, score is now  69\n",
      "Correct, score is now  70\n",
      "Correct, score is now  71\n",
      "Correct, score is now  72\n",
      "Correct, score is now  73\n",
      "Correct, score is now  74\n",
      "Correct, score is now  75\n",
      "Correct, score is now  76\n",
      "Correct, score is now  77\n",
      "Correct, score is now  78\n",
      "Correct, score is now  79\n",
      "Correct, score is now  80\n",
      "Correct, score is now  81\n",
      "Correct, score is now  82\n",
      "Correct, score is now  83\n",
      "Correct, score is now  84\n",
      "Correct, score is now  85\n",
      "Correct, score is now  86\n",
      "Correct, score is now  87\n",
      "Correct, score is now  88\n",
      "Correct, score is now  89\n",
      "Correct, score is now  90\n",
      "Correct, score is now  91\n",
      "Correct, score is now  92\n",
      "Correct, score is now  93\n",
      "Correct, score is now  94\n",
      "Correct, score is now  95\n",
      "Correct, score is now  96\n",
      "Correct, score is now  97\n",
      "Correct, score is now  98\n",
      "Correct, score is now  99\n",
      "Correct, score is now  100\n",
      "Correct, score is now  101\n",
      "Correct, score is now  102\n",
      "Correct, score is now  103\n",
      "Correct, score is now  104\n",
      "Correct, score is now  105\n",
      "Correct, score is now  106\n",
      "Correct, score is now  107\n",
      "Correct, score is now  108\n",
      "Correct, score is now  109\n",
      "Correct, score is now  110\n",
      "Correct, score is now  111\n",
      "Correct, score is now  112\n",
      "Correct, score is now  113\n",
      "Correct, score is now  114\n",
      "Correct, score is now  115\n",
      "Correct, score is now  116\n",
      "Correct, score is now  117\n",
      "Correct, score is now  118\n",
      "Correct, score is now  119\n",
      "Correct, score is now  120\n",
      "Correct, score is now  121\n",
      "Correct, score is now  122\n",
      "Correct, score is now  123\n",
      "Correct, score is now  124\n",
      "Correct, score is now  125\n",
      "Correct, score is now  126\n",
      "Correct, score is now  127\n",
      "Correct, score is now  128\n",
      "Correct, score is now  129\n",
      "Correct, score is now  130\n",
      "Correct, score is now  131\n",
      "Correct, score is now  132\n",
      "Correct, score is now  133\n",
      "Correct, score is now  134\n",
      "Correct, score is now  135\n",
      "Correct, score is now  136\n",
      "Correct, score is now  137\n",
      "Correct, score is now  138\n",
      "Correct, score is now  139\n",
      "Correct, score is now  140\n",
      "Correct, score is now  141\n",
      "Correct, score is now  142\n",
      "Correct, score is now  143\n",
      "Correct, score is now  144\n",
      "Correct, score is now  145\n",
      "Correct, score is now  146\n",
      "Incorrect Score for subject  146\n",
      "Correct, score is now  147\n",
      "Correct, score is now  148\n",
      "Correct, score is now  149\n",
      "Correct, score is now  150\n",
      "Correct, score is now  151\n",
      "Correct, score is now  152\n",
      "Incorrect Score for subject  153\n",
      "Correct, score is now  153\n",
      "Correct, score is now  154\n",
      "Correct, score is now  155\n",
      "Correct, score is now  156\n",
      "Correct, score is now  157\n",
      "Correct, score is now  158\n",
      "Correct, score is now  159\n",
      "Correct, score is now  160\n",
      "Correct, score is now  161\n",
      "Correct, score is now  162\n",
      "Correct, score is now  163\n",
      "Correct, score is now  164\n",
      "Correct, score is now  165\n",
      "Correct, score is now  166\n",
      "Correct, score is now  167\n",
      "Correct, score is now  168\n",
      "Correct, score is now  169\n",
      "Correct, score is now  170\n",
      "Correct, score is now  171\n",
      "Correct, score is now  172\n",
      "Incorrect Score for subject  174\n",
      "Correct, score is now  173\n",
      "Correct, score is now  174\n",
      "Correct, score is now  175\n",
      "Correct, score is now  176\n",
      "Correct, score is now  177\n",
      "Correct, score is now  178\n",
      "Correct, score is now  179\n",
      "Correct, score is now  180\n",
      "Correct, score is now  181\n",
      "Correct, score is now  182\n",
      "Correct, score is now  183\n",
      "Correct, score is now  184\n",
      "Correct, score is now  185\n",
      "Correct, score is now  186\n",
      "Correct, score is now  187\n",
      "Correct, score is now  188\n",
      "Correct, score is now  189\n",
      "Correct, score is now  190\n",
      "Correct, score is now  191\n",
      "Correct, score is now  192\n",
      "Correct, score is now  193\n",
      "Correct, score is now  194\n",
      "Correct, score is now  195\n",
      "Correct, score is now  196\n",
      "Correct, score is now  197\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'total_subjects' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_5644/1494146958.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Incorrect Score for subject '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Accuracy = '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mtotal_subjects\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'total_subjects' is not defined"
     ]
    }
   ],
   "source": [
    "score = 0\n",
    "training_size = int((2/3)*data.shape[2])\n",
    "testing_size = int((1/3)*data.shape[2])\n",
    "for i in range(testing_size):\n",
    "    likelihood_list = []\n",
    "    for j in range(testing_size):\n",
    "        likelihood = (-0.5)*math.log(np.linalg.det(cov[j])) - (0.5)*np.dot( testing_data[i]-mu[j], np.dot( np.linalg.inv(cov[j]), (testing_data[i]-mu[j]).T ) )\n",
    "        likelihood_list.append(likelihood)\n",
    "    temp = np.array(likelihood_list)\n",
    "    if np.argmax(temp) == i:\n",
    "        score += 1\n",
    "        print('Correct, score is now ', score)\n",
    "    else:\n",
    "        print('Incorrect Score for subject ', i)\n",
    "print('Accuracy = ', (score*100/total_subjects))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_subjects = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy =  98.5\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy = ', (score*100/total_subjects))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cdfa986811ede5aec55e936b833b50dd727f4374221054198d85d31e15300e88"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
